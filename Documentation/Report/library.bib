Automatically generated by Mendeley 1.3.1
Any changes to this file will be lost if it is regenerated by Mendeley.

@misc{data:glass,
title = {{Glass Identification Database}},
url = {http://archive.ics.uci.edu/ml/machine-learning-databases/glass/}
}
@techreport{Settles2010,
abstract = {The key idea behind active learning is that a machine learning algorithm can achieve greater accuracy with fewer training labels if it is allowed to choose the data from which it learns. An active learner may pose queries, usually in the form of unlabeled data instances to be labeled by an oracle (e.g., a human annotator). Active learning is well-motivated in many modern machine learning problems, where unlabeled data may be abundant or easily obtained, but labels are difficult, time-consuming, or expensive to obtain. This report provides a general introduction to active learning and a survey of the literature. This includes a discussion of the scenarios in which queries can be formulated, and an overview of the query strategy frameworks proposed in the literature to date. An analysis of the empirical and theoretical evidence for successful active learning, a summary of problem setting variants and practical issues, and a discussion of related topics in machine learning research are also presented.},
annote = {
        From Duplicate 1 ( 
        
          Active Learning Literature Survey
        
         - Settles, Burr )

        
        

        From Duplicate 2 ( 
        
          Active Learning Literature Survey
        
         - Settles, Burr )

        
        

        

        

        

        

        From Duplicate 2 ( 
        
          Active Learning Literature Survey
        
         - Settles, Burr )

        
        

        

        

      },
author = {Settles, Burr},
booktitle = {SciencesNew York},
doi = {10.1.1.167.4245},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Active Learning Literature Survey - 2009 - Settles(2).pdf:pdf;:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Active Learning Literature Survey - 2009 - Settles.pdf:pdf},
institution = {University of Wisconsin--Madison},
number = {2},
pages = {201--221},
publisher = {Citeseer},
series = {Computer Sciences Technical Report},
title = {{Active Learning Literature Survey}},
type = {Computer Sciences Technical Report},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.167.4245\&amp;rep=rep1\&amp;type=pdf},
volume = {15},
year = {2009}
}
@inproceedings{data:breathalyzer,
author = {{D. Doyle} and {P. Cunningham} and {D.G. Bridge} and {Y. Rahman}},
booktitle = {Procs. of the 7th European Conference on Case-Based Reasoning},
editor = {{P. Funk} and {P. Gonz\'{a}lez-Calero}},
pages = {157--168},
publisher = {Springer},
series = {LNCS-3155},
title = {{Explanation Oriented Retrieval}},
year = {2004}
}
@phdthesis{Cummins-forthcoming,
author = {Cummins, L},
school = {Department of Computer Science, University College Cork, Ireland},
title = {{Combining and Choosing Case Base Maintenance Algorithms}}
}
@phdthesis{BridgeUpcoming,
author = {Cummins, L.},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Combining and Choosing Case Base Maintenance Algorithms (Upcoming) - 2011 - Cummins.pdf:pdf},
school = {Department of Computer Science, University College Cork, Ireland},
title = {{Combining and Choosing Case Base Maintenance Algorithms (Upcoming)}},
year = {2011}
}
@phdthesis{Hu2011,
author = {Hu, Rong},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Active Learning for Text Classification - 2011 - Hu.pdf:pdf},
school = {Dublin Institute of Technology},
title = {{Active Learning for Text Classification}},
url = {http://arrow.dit.ie/sciendoc/115/},
year = {2011}
}
@misc{data:breathalyzer,
abstract = {Obtained from Dr. Derek Bridge},
title = {{Dublin Breathalyzer Data}}
}
@article{Settles2010,
abstract = {The key idea behind active learning is that a machine learning algorithm can achieve greater accuracy with fewer training labels if it is allowed to choose the data from which it learns. An active learner may pose queries, usually in the form of unlabeled data instances to be labeled by an oracle (e.g., a human annotator). Active learning is well-motivated in many modern machine learning problems, where unlabeled data may be abundant or easily obtained, but labels are difficult, time-consuming, or expensive to obtain. This report provides a general introduction to active learning and a survey of the literature. This includes a discussion of the scenarios in which queries can be formulated, and an overview of the query strategy frameworks proposed in the literature to date. An analysis of the empirical and theoretical evidence for successful active learning, a summary of problem setting variants and practical issues, and a discussion of related topics in machine learning research are also presented.},
author = {Settles, Burr},
doi = {10.1.1.167.4245},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Active Learning Literature Survey - 2009 - Settles(2).pdf:pdf},
institution = {University of Wisconsin--Madison},
journal = {SciencesNew York},
number = {2},
pages = {201--221},
publisher = {Citeseer},
series = {Computer Sciences Technical Report},
title = {{Active Learning Literature Survey}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.167.4245\&amp;rep=rep1\&amp;type=pdf},
volume = {15},
year = {2010}
}
@inproceedings{Smyth95rememberingto,
author = {Smyth, Barry and Keane, Mark T},
pages = {377--382},
publisher = {Morgan Kaufmann},
title = {{Remembering To Forget: A Competence-Preserving Case Deletion Policy for Case-Based Reasoning Systems}},
year = {1995}
}
@phdthesis{citeulike:947572,
abstract = {Cluster analysis refers to a family of procedures which are fundamentally concerned with automatically arranging data into meaningful groups. These procedures are increasingly being employed in knowledge discovery tasks to assist in the exploration and interpretation of large datasets. Since users may often be unfamiliar with the exact contents of a dataset, clustering can provide a means of introducing some form of organisation to the data, which can also serve to highlight significant patterns and trends. Cluster analysis methods have recently become an important part of commercial and industrial applications for mining data in a variety of domains. In the past, these methods have also been employed to facilitate the discovery of knowledge from large collections of unstructured text. Renewed interest in document clustering has been prompted by the exponential growth in the size of digital document collections, including web pages, e-mail messages and news articles. Another motivating factor has been the increased availability of computing resources, which has encouraged researchers to reconsider the application of machine learning methods to larger corpora. A variety of techniques for generating and evaluating clusterings of text data have been proposed in the literature, which differ significantly in terms of their theoretical foundations and practical implementation. A significant obstacle for researchers interested in harnessing this work is the absence of a comprehensive framework for comparing and extending these techniques. In this thesis, we introduce the Text Clustering Toolkit (TCT), a state-of-the-art framework supporting the development of applications for unsupervised text mining tasks. The toolkit covers all phases of the cluster analysis process, from the preprocessing of raw documents to the interpretation of a final clustering solution. As well as allowing researchers to evaluate popular learning algorithms, TCT also provides a flexible test-bed for the design and the development of novel clustering procedures. The primary focus of a significant body of research in document clustering has been concerned with the production of solutions that are "accurate" in the sense that they succeed in revealing the underlying structure of a dataset. This thesis proposes a selection of novel clustering algorithms, which frequently succeed in accurately identifying the natural trends and groups in document collections. We also describe new strategies to improve the accuracy afforded by existing algorithms, such as those based on kernel learning. A secondary objective, which is frequently overlooked in this area, is the provision of information to help a user interpret the output of an analysis procedure. To support the extraction of knowledge from clustering solutions, techniques are described for producing summary information, in the form of human-interpretable cluster labels. The increase in computing power available to researchers has opened up many new possibilities, such as the study of methods that involve aggregating information obtained from multiple clusterings. This information can often provide additional insight regarding the group structures in a dataset. However, due to the exceptionally large size and highdimensional nature of real-world document collections, the computational cost of applying aggregation methods to text data will generally be prohibitive. To address this scalability problem, we introduce novel techniques for efficiently generating and combining a diverse collection of clusterings to produce more accurate document clustering solutions. A particularly problematic aspect of many common unsupervised learning procedures relates to the selection of key algorithm parameters, which can greatly dictate the success of the procedure. To this end, we explore ways in which the aggregation of information derived from a large collection of clusterings can provide us with clues about the validity of a clustering model. We devote particular attention to the estimation of the number of natural groups or topics in a text corpus, which represents a fundamental issue when employing well-known document clustering algorithms.},
author = {Greene, Derek},
keywords = {clustering},
month = oct,
school = {Trinity College Dublin},
title = {{A State-of-the-Art Toolkit for Document Clustering}},
year = {2006}
}
@misc{prog:ubuntu,
title = {{Ubuntu}},
url = {http://www.ubuntu.org},
year = {2004}
}
@misc{prog:pythonsty,
title = {{Python.sty}},
url = {http://weongyo.org/docs/SpiderMonkey/python.sty}
}
@article{Guan2008,
author = {Guan, Donghai and Yuan, Weiwei and Lee, Young-Koo and Gavrilov, Andrey and Lee, Sungyoung},
issn = {1064-1246},
journal = {Journal of Intelligent \& Fuzzy Systems: Applications in Engineering and Technology},
keywords = {Classification,border-based selection,center-based selection,data selection,fuzzy clustering,hybrid selection},
month = dec,
number = {4,5},
pages = {321--334},
title = {{Improving supervised learning performance by using fuzzy clustering method to select training data}},
url = {http://dl.acm.org/citation.cfm?id=1454295.1454302},
volume = {19},
year = {2008}
}
@misc{prog:lyx,
title = {{LyX}},
url = {http://www.lyx.org/},
year = {1995}
}
@misc{data:Comp,
title = {comp.sys.ibm.pc.hardware vs comp.sys.mac.hardware},
url = {http://people.csail.mit.edu/jrennie/20Newsgroups/}
}
@incollection{Hu2010,
annote = {        From Duplicate 1 (                           EGAL: Exploration Guided Active Learning for TCBR                         - Hu, Rong; Jane Delany, Sarah; Mac Namee, Brian )
                
        From Duplicate 1 (                           EGAL: Exploration Guided Active Learning for TCBR                         - Hu, Rong; Jane Delany, Sarah; Mac Namee, Brian )
                
10.1007/978-3-642-14274-1\_13
        
        From Duplicate 2 (                           EGAL: Exploration Guided Active Learning for TCBR                         - Hu, Rong; Jane Delany, Sarah; Mac Namee, Brian )
                
        From Duplicate 1 (                           EGAL: Exploration Guided Active Learning for TCBR                         - Hu, Rong; Jane Delany, Sarah; Mac Namee, Brian )
                
10.1007/978-3-642-14274-1\_13
        
        
        
        
        
        From Duplicate 2 (                           EGAL: Exploration Guided Active Learning for TCBR                         - Hu, Rong; Jane Delany, Sarah; Mac Namee, Brian )
                
10.1007/978-3-642-14274-1\_13
        
      },
author = {Hu, Rong and {Jane Delany}, Sarah and {Mac Namee}, Brian},
booktitle = {Case-Based Reasoning. Research and Development},
editor = {Bichindaritz, Isabelle and Montani, Stefania},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/EGAL Exploration Guided Active Learning for TCBR - 2010 - Hu, Jane Delany, Mac Namee.pdf:pdf},
isbn = {978-3-642-14273-4},
pages = {156--170},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{EGAL: Exploration Guided Active Learning for TCBR}},
url = {http://dx.doi.org/10.1007/978-3-642-14274-1\_13},
volume = {6176},
year = {2010}
}
@article{Settles2010,
author = {Settles, Burr},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Active Learning Literature Survey - 2009 - Settles.pdf:pdf},
journal = {Sciences-New York},
title = {{Active Learning Literature Survey}},
year = {2010}
}
@misc{prog:matplotlib,
title = {{Matplotlib}},
url = {http://matplotlib.sourceforge.net/},
year = {2008}
}
@incollection{Delany2005,
annote = {        From Duplicate 1 (                   Generating Estimates of Classification Confidence for a Case-Based Spam Filter                 - Delany, Sarah; Cunningham, P\'{a}draig; Doyle, D\'{o}nal; Zamolotskikh, Anton )
                
10.1007/11536406\_16
        
        From Duplicate 2 (                   Generating estimates of classification confidence for a case-based spam filter                 - Delany, S.J.; Cunningham, P.; Doyle, D.; Zamolotskikh, A. )
                
        
        
      },
author = {Delany, S.J. Sarah and Cunningham, P\'{a}draig and Doyle, D\'{o}nal and Zamolotskikh, Anton},
booktitle = {Case-Based Reasoning Research and Development},
editor = {Mu\~{n}oz-\'{A}vila, H\'{e}ctor and Ricci, Francesco},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Generating estimates of classification confidence for a case-based spam filter - 2005 - Delany et al.pdf:pdf},
isbn = {978-3-540-28174-0},
pages = {177--190},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Generating estimates of classification confidence for a case-based spam filter}},
url = {http://dx.doi.org/10.1007/11536406\_16},
volume = {3620},
year = {2005}
}
@article{Haertel,
author = {Haertel, R and Seppi, KD and Ringger, EK},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Return on investment for active learning - 2009 - Haertel, Seppi, Ringger.pdf:pdf},
journal = {on Cost Sensitive Learning},
pages = {1--8},
title = {{Return on investment for active learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.148.9408\&amp;rep=rep1\&amp;type=pdf},
year = {2009}
}
@misc{prog:pythonbrew,
title = {{PythonBrew}},
url = {http://pypi.python.org/pypi/pythonbrew}
}
@misc{prog:eclipse,
title = {{Eclipse}},
url = {http://www.eclipse.org/},
year = {2004}
}
@misc{prog:extraplaceins,
title = {extraplaceins},
url = {http://lexfridman.com/blogs/research/2011/03/06/prevent-figures-from-floating-outside-sections-in-latex/}
}
@misc{data:lungcancer,
title = {{Lung Cancer Data}},
url = {http://archive.ics.uci.edu/ml/machine-learning-databases/lung-cancer/}
}
@misc{prog:lsprof,
title = {lsprof},
url = {https://code.launchpad.net/lsprof}
}
@inproceedings{Balcan2008,
author = {Balcan, M F and Hanneke, S and Wortman, J},
booktitle = {COLT},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//The true sample complexity of active learning - 2008 - Balcan, Hanneke, Wortman.pdf:pdf},
pages = {45--56},
publisher = {Springer},
title = {{The true sample complexity of active learning}},
year = {2008}
}
@misc{prog:putty,
title = {{PuTTY}},
url = {http://www.chiark.greenend.org.uk/~sgtatham/putty/}
}
@incollection{springerlink:10.1007/978-3-642-14274-1_13,
annote = {10.1007/978-3-642-14274-1\_13},
author = {Hu, Rong and {Jane Delany}, Sarah and {Mac Namee}, Brian},
booktitle = {Case-Based Reasoning. Research and Development},
editor = {Bichindaritz, Isabelle and Montani, Stefania},
isbn = {978-3-642-14273-4},
pages = {156--170},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{EGAL: Exploration Guided Active Learning for TCBR}},
url = {http://dx.doi.org/10.1007/978-3-642-14274-1\_13},
volume = {6176},
year = {2010}
}
@article{Chakraborty,
author = {Chakraborty, Shayok and Balasubramanian, Vineeth},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//An Optimization Based Framework for Dynamic Batch Mode Active Learning - 2010 - Chakraborty, Balasubramanian.pdf:pdf},
journal = {opt.kyb.tuebingen.mpg.de},
pages = {1--6},
title = {{An Optimization Based Framework for Dynamic Batch Mode Active Learning}},
url = {http://opt.kyb.tuebingen.mpg.de/papers/OPT2010-chakraborty.pdf},
year = {2010}
}
@article{Lindstrom2010,
author = {Lindstrom, Patrick and Hu, R. and Delany, S.J. and {Mac Namee}, B.},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//SVM Based Active Learning with Exploration - 2010 - Lindstrom et al.pdf:pdf},
journal = {Electrical Engineering},
pages = {1--3},
title = {{SVM Based Active Learning with Exploration}},
url = {http://arrow.dit.ie/cgi/viewcontent.cgi?article=1127\&amp;context=engscheleart},
year = {2010}
}
@misc{web:uci,
title = {{UCI Machine Learning Repository}},
url = {http://archive.ics.uci.edu/ml/}
}
@misc{web:scikitpullreq,
title = {{SciKit Learn Open Source Bug Identification and Resolution Contribution.}},
url = {https://github.com/scikit-learn/scikit-learn/pull/577}
}
@inproceedings{Ng2007,
abstract = {Owing to the growth of Internet and computer technology, pattern recognition for large-scale datasets has become one of the hot research topics. The major challenges are to reduce the human efforts involved and to improve the efficiency. Traditional passive learning methods require labeling of all training samples may not be feasible in large-scale recognition problems because of the requirement of large-scale class labeling for the huge number of training samples. In the literatures, there are many studies on active learning methods, which does not require all training samples to be labeled and it selects training samples for labeling based on the knowledge of the current classifier. In this paper, we present an active learning method using localized generalization error of candidate sample as selection criterion. Our method uses the generalization error of candidate sample, so theoretically it should have a better performance than other methods. From the experiment results, our method outperforms other methods in both yielding higher prediction accuracy on testing dataset and selecting fewer training samples. Furthermore, we propose a heuristics improvement based on the Q -neighborhood idea of the localized generalization error model to reduce the number of samples being selected and the computational time.},
author = {Ng, Wing W. Y. and Sun, Binbin and Yeung, Daniel S.},
booktitle = {2007 IEEE International Conference on Systems, Man and Cybernetics},
doi = {10.1109/ICSMC.2007.4413940},
isbn = {978-1-4244-0990-7},
pages = {3588--3593},
publisher = {IEEE},
title = {{Heuristic improvement for active learning using localized generalization error as selection criterion}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4413940},
year = {2007}
}
@misc{prog:pygraphviz,
title = {{PyGraphviz}},
url = {http://networkx.lanl.gov/pygraphviz/}
}
@article{data:zoo,
title = {{Zoo database}},
url = {http://archive.ics.uci.edu/ml/machine-learning-databases/zoo/}
}
@misc{prog:pydev,
title = {{PyDev}},
url = {http://pydev.org/}
}
@misc{prog:latex,
title = {{LaTeX}},
url = {http://www.latex-project.org/},
year = {1980}
}
@misc{data:WinXwin,
title = {comp.windows.x vs comp.os.ms-windows.misc},
url = {http://people.csail.mit.edu/jrennie/20Newsgroups/}
}
@misc{prog:cprofile,
title = {{cProfile}},
url = {http://docs.python.org/library/profile.html\#module-cProfile}
}
@article{Vinzamuri2010,
author = {Vinzamuri, Bhanukiran},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//A Robust Active Learning Framework using Itemset based Dynamic Rule Sampling - 2010 - Vinzamuri.pdf:pdf},
journal = {Architecture},
title = {{A Robust Active Learning Framework using Itemset based Dynamic Rule Sampling}},
year = {2010}
}
@misc{data:iris,
title = {{Iris Plants Database}},
url = {http://archive.ics.uci.edu/ml/machine-learning-databases/iris/}
}
@misc{prog:weka,
title = {{Weka}},
url = {http://www.cs.waikato.ac.nz/ml/weka/},
year = {1997}
}
@techreport{settles.tr09,
author = {Settles, Burr},
institution = {University of Wisconsin--Madison},
number = {1648},
title = {{Active Learning Literature Survey}},
type = {Computer Sciences Technical Report},
year = {2009}
}
@article{Cebron2008,
abstract = {Classifying large datasets without any a-priori information poses a problem in numerous tasks. Especially in industrial environments, we often encounter diverse measurement devices and sensors that produce huge amounts of data, but we still rely on a human expert to help give the data a meaningful interpretation. As the amount of data that must be manually classified plays a critical role,we need to reduce the number of learning episodes involving human interactions as much as possible. In addition for real world applications it is fundamental to converge in a stable manner to a solution that is close to the optimal solution. We present a new self-controlled exploration/exploitation strategy to select data points to be labeled by a domain expert where the potential of each data point is computed based on a combination of its representativeness and the uncertainty of the classifier. A new Prototype Based Active Learning (PBAC) algorithm for classification is introduced. We compare the results to other active learning approaches on several benchmark datasets.},
author = {Cebron, Nicolas and Berthold, Michael R.},
doi = {10.1007/s10618-008-0115-0},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Active learning for object classification from exploration to exploitation - 2008 - Cebron, Berthold.pdf:pdf},
issn = {13845810},
journal = {Data Mining and Knowledge Discovery},
keywords = {active learning,data mining,exploitation,exploration,prototype classification,subtractive clustering},
month = jul,
number = {2},
pages = {283--299},
title = {{Active learning for object classification: from exploration to exploitation}},
url = {http://www.springerlink.com/index/10.1007/s10618-008-0115-0},
volume = {18},
year = {2008}
}
@misc{prog:tortoisegit,
title = {{TortoiseGit}},
url = {http://code.google.com/p/tortoisegit/}
}
@article{Zhu2008,
address = {Morristown, NJ, USA},
author = {Zhu, Jingbo and Wang, Huizhen and Yao, Tianshun and Tsou, Benjamin K.},
doi = {10.3115/1599081.1599224},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Active learning with sampling by uncertainty and density for word sense disambiguation and text classification - 2008 - Zhu et al.pdf:pdf},
isbn = {9781905593446},
journal = {Proceedings of the 22nd International Conference on Computational Linguistics - COLING '08},
number = {August},
pages = {1137--1144},
publisher = {Association for Computational Linguistics},
title = {{Active learning with sampling by uncertainty and density for word sense disambiguation and text classification}},
url = {http://portal.acm.org/citation.cfm?doid=1599081.1599224},
volume = {1},
year = {2008}
}
@incollection{springerlink:10.1007/11871842_68,
annote = {10.1007/11871842\_68},
author = {K\"{o}rner, Christine and Wrobel, Stefan},
booktitle = {Machine Learning: ECML 2006},
editor = {F\"{u}rnkranz, Johannes and Scheffer, Tobias and Spiliopoulou, Myra},
isbn = {978-3-540-45375-8},
pages = {687--694},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Multi-class Ensemble-Based Active Learning}},
url = {http://dx.doi.org/10.1007/11871842\_68},
volume = {4212},
year = {2006}
}
@article{Hu2010,
author = {Hu, Rong and Namee, Brian Mac and Delany, Sarah Jane},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Off to a Good Start Using Clustering to Select the Initial Training Set in Active Learning - 2010 - Hu, Namee, Delany.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {general conference papers},
number = {Flairs},
pages = {26--31},
title = {{Off to a Good Start : Using Clustering to Select the Initial Training Set in Active Learning}},
year = {2010}
}
@article{Zhao2008,
author = {Zhao, Wentao and Long, Jun and Zhu, En and Liu, Yun},
journal = {Frontiers in Algorithmics},
keywords = {active learning,graph based learning},
number = {x},
pages = {311--322},
publisher = {Springer},
title = {{A Scalable Algorithm for Graph-Based Active}},
url = {http://www.springerlink.com/index/835ml8m5v8028217.pdf},
year = {2008}
}
@article{Xu2007,
author = {Xu, Zuobing and Akella, Ram and Zhang, Yi},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Incorporating diversity and density in active learning for relevance feedback - 2007 - Xu, Akella, Zhang(2).pdf:pdf},
journal = {Advances in Information Retrieval},
keywords = {density\_measure},
mendeley-tags = {density\_measure},
pages = {246--257},
publisher = {Springer},
title = {{Incorporating diversity and density in active learning for relevance feedback}},
url = {http://www.springerlink.com/index/J20663R2R1116141.pdf},
year = {2007}
}
@incollection{springerlink:10.1007/978-3-540-24775-3_37,
annote = {10.1007/978-3-540-24775-3\_37},
author = {Mandvikar, Amit and Liu, Huan and Motoda, Hiroshi},
booktitle = {Advances in Knowledge Discovery and Data Mining},
editor = {Dai, Honghua and Srikant, Ramakrishnan and Zhang, Chengqi},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Compact Dual Ensembles for Active Learning - 2004 - Mandvikar, Liu, Motoda.pdf:pdf},
isbn = {978-3-540-22064-0},
pages = {293--297},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Compact Dual Ensembles for Active Learning}},
url = {http://dx.doi.org/10.1007/978-3-540-24775-3\_37},
volume = {3056},
year = {2004}
}
@article{Settles2010,
abstract = {The key idea behind active learning is that a machine learning algorithm can achieve greater accuracy with fewer training labels if it is allowed to choose the data from which it learns. An active learner may pose queries, usually in the form of unlabeled data instances to be labeled by an oracle (e.g., a human annotator). Active learning is well-motivated in many modern machine learning problems, where unlabeled data may be abundant or easily obtained, but labels are difficult, time-consuming, or expensive to obtain. This report provides a general introduction to active learning and a survey of the literature. This includes a discussion of the scenarios in which queries can be formulated, and an overview of the query strategy frameworks proposed in the literature to date. An analysis of the empirical and theoretical evidence for successful active learning, a summary of problem setting variants and practical issues, and a discussion of related topics in machine learning research are also presented.},
author = {Settles, Burr},
doi = {10.1.1.167.4245},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Active Learning Literature Survey - 2009 - Settles(2).pdf:pdf},
institution = {University of Wisconsin--Madison},
journal = {SciencesNew York},
number = {2},
pages = {201--221},
publisher = {Citeseer},
series = {Computer Sciences Technical Report},
title = {{Active Learning Literature Survey}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.167.4245\&amp;rep=rep1\&amp;type=pdf},
volume = {15},
year = {2010}
}
@incollection{springerlink:10.1007/978-3-642-02998-1_11,
annote = {10.1007/978-3-642-02998-1\_11},
author = {Delany, Sarah},
booktitle = {Case-Based Reasoning Research and Development},
editor = {McGinty, Lorraine and Wilson, David},
isbn = {978-3-642-02997-4},
pages = {135--149},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{The Good, the Bad and the Incorrectly Classified: Profiling Cases for Case-Base Editing}},
url = {http://dx.doi.org/10.1007/978-3-642-02998-1\_11},
volume = {5650},
year = {2009}
}
@misc{prog:winscp,
title = {{WinSCP}},
url = {http://winscp.net/eng/index.php},
year = {2000}
}
@misc{prog:python,
title = {{Python}},
url = {http://www.python.org}
}
@misc{prog:eclipse,
title = {{Eclipse}},
url = {http://eclipse.org/}
}
@misc{prog:nose,
title = {{Nose}},
url = {https://github.com/nose-devs/nose}
}
@article{Baram2004,
author = {Baram, Yoram and El-Yaniv, R},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Online choice of active learning algorithms - 2004 - Baram, El-Yaniv.pdf:pdf},
journal = {The Journal of Machine Learning},
title = {{Online choice of active learning algorithms}},
url = {http://portal.acm.org/citation.cfm?id=1005342},
year = {2004}
}
@misc{prog:pyx,
title = {{PyX}},
url = {http://pyx.sourceforge.net/},
year = {2002}
}
@misc{prog:runsnakerun,
title = {{RunSnakeRun}},
url = {http://www.vrplumber.com/programming/runsnakerun/}
}
@article{Settles2008,
abstract = {Both multiple-instance learning and active learning are widely employed in image categorization, but generally they are applied separately. This paper studies the integration of these two methods. Different from typical active learning approaches, the sample selection strategy in multiple-instance active learning needs to handle samples in different granularities, that is, instance/region and bag/image. Three types of sample selection strategies are evaluated: (1) selecting bags only; (2) selecting instances only; and (3) selecting both bags and instances. As there is no existing method for the third case, we propose a set kernel based classifier, based on which, a unified bag and/or instance selection criterion and an integrated learning algorithm are built. The experiments on Corel dataset show that selecting both bags and instances outperforms the other two strategies.},
author = {Settles, B and Craven, M and Ray, S},
editor = {Platt, J C and Koller, D and Singer, Y and Roweis, S},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Multiple-Instance Active Learning - 2008 - Settles, Craven, Ray.pdf:pdf},
journal = {Learning},
pages = {1289--1296},
publisher = {Citeseer},
title = {{Multiple-Instance Active Learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.143.6305},
volume = {1},
year = {2008}
}
@article{Cohn1996,
author = {Cohn, David A and Jordan, Michael I},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Active Learning with Statistical Models - 1996 - Cohn, Jordan.pdf:pdf},
journal = {Learning},
pages = {129--145},
title = {{Active Learning with Statistical Models}},
volume = {4},
year = {1996}
}
@inproceedings{Lewis1994,
author = {Lewis, D.D. and Gale, W.A.},
booktitle = {Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/A sequential algorithm for training text classifiers - 1994 - Lewis, Gale.pdf:pdf},
pages = {3--12},
publisher = {Springer-Verlag New York, Inc.},
title = {{A sequential algorithm for training text classifiers}},
url = {http://dl.acm.org/citation.cfm?id=188490.188495},
year = {1994}
}
@misc{data:Vehicle,
title = {rec.autos vs rec.motorcycles},
url = {http://people.csail.mit.edu/jrennie/20Newsgroups/}
}
@misc{prog:sklearn,
title = {{SciKit Learn}},
url = {http://scikit-learn.org/}
}
@misc{prog:pypdf,
title = {{pyPdf}},
url = {http://pybrary.net/pyPdf/}
}
@article{He,
author = {He, Jingrui},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Nearest-neighbor-based active learning for rare category detection - 2007 - He.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {1--8},
title = {{Nearest-neighbor-based active learning for rare category detection}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.69.1601\&amp;rep=rep1\&amp;type=pdf},
year = {2007}
}
@inproceedings{Guo2007a,
abstract = {An "active learning system" will sequentially decide which unlabeled instance to label, with the goal of efficiently gathering the information necessary to produce a good classifier. Some such systems greedily select the next instance based only on properties of that instance and the few currently labeled points - e.g., selecting the one closest to the current classification boundary. Unfortunately, these approaches ignore the valuable information contained in the other unlabeled instances, which can help identify a good classifier much faster. For the previous approaches that do exploit this unlabeled data, this information is mostly used in a conservative way. One common property of the approaches in the literature is that the active learner sticks to one single query selection criterion in the whole process. We propose a system, MM+M, that selects the query instance that is able to provide the maximum conditional mutual information about the labels of the unlabeled instances, given the labeled data, in an optimistic way. This approach implicitly exploits the discriminative partition information contained in the unlabeled data. Instead of using one selection criterion, MM+M also employs a simple on-line method that changes its selection rule when it encounters an "unexpected label". Our empirical results demonstrate that this new approach works effectively.},
author = {Guo, Yuhong and Greiner, Russ},
booktitle = {IJCAI},
keywords = {learning},
pages = {823--829},
title = {{Optimistic active learning using mutual information}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Optimistic+Active+Learning+using+Mutual+Information\#0},
volume = {7},
year = {2007}
}
@misc{prog:pypy,
title = {{PyPy}},
url = {http://pypy.org/}
}
@article{Lan2011,
author = {Lan, Liang and Shi, H and Wang, Zhuang and Vucetic, S},
journal = {jmlrcsailmitedu},
keywords = {active learning,clustering,ensemble classifiers,feature filter,parzen window},
pages = {99--112},
title = {{An Active Learning Algorithm Based on Parzen Window Classification}},
url = {http://jmlr.csail.mit.edu/proceedings/papers/v16/lan11a/lan11a.pdf},
volume = {16},
year = {2011}
}
@misc{prog:libreoffice,
title = {{LibreOffice}},
url = {http://www.libreoffice.org/},
year = {1999}
}
@article{Beygelzimer2008,
abstract = {We present a practical and statistically consistent scheme for actively learning binary classifiers under general loss functions. Our algorithm uses importance weighting to correct sampling bias, and by controlling the variance, we are able to give rigorous label complexity bounds for the learning process. Experiments on passively labeled data show that this approach reduces the label complexity required to achieve good predictive performance on many learning problems.},
author = {Beygelzimer, Alina and Dasgupta, Sanjoy and Langford, John},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Importance Weighted Active Learning - 2008 - Beygelzimer, Dasgupta, Langford.pdf:pdf},
journal = {Proceedings of the 26th Annual International Conference on Machine Learning ICML 09},
number = {ii},
pages = {1--8},
publisher = {ACM Press},
series = {ICML '09},
title = {{Importance Weighted Active Learning}},
url = {http://arxiv.org/abs/0812.4952},
volume = {abs/0812.4},
year = {2008}
}
@incollection{springerlink:10.1007/978-3-642-00831-3_1,
annote = {10.1007/978-3-642-00831-3\_1},
author = {Zhu, Jingbo and Wang, Huizhen and Tsou, Benjamin},
booktitle = {Computer Processing of Oriental Languages. Language Technology for the Knowledge-based Economy},
editor = {Li, Wenjie and Moll\'{a}-Aliod, Diego},
isbn = {978-3-642-00830-6},
pages = {1--10},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Density-Based Re-ranking Technique for Active Learning for Data Annotations}},
url = {http://dx.doi.org/10.1007/978-3-642-00831-3\_1},
volume = {5459},
year = {2009}
}
@misc{data:tae,
title = {{Teaching Assistant Evaluation}},
url = {http://archive.ics.uci.edu/ml/machine-learning-databases/tae/}
}
@misc{prog:numpy,
title = {{NumPy}},
url = {http://numpy.scipy.org/},
year = {1995}
}
@inproceedings{Smyth1995,
annote = {        From Duplicate 2 (                   Remembering To Forget A Competence-Preserving Case Deletion Policy for Case-Based Reasoning Systems                 - Smyth, Barry )
                
        
        
      },
author = {Smyth, Barry and Keane, Mark T},
booktitle = {Proceedings of the 14th International Joint Conference},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Remembering To Forget A Competence-Preserving Case Deletion Policy for Case-Based Reasoning Systems - Unknown - Smyth.pdf:pdf},
pages = {377--382},
publisher = {Morgan Kaufmann},
title = {{Remembering To Forget: A Competence-Preserving Case Deletion Policy for Case-Based Reasoning Systems}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.2767},
year = {1995}
}
@phdthesis{Greene2007,
abstract = {Cluster analysis refers to a family of procedures which are fundamentally concerned with automatically arranging data into meaningful groups. These procedures are increasingly being employed in knowledge discovery tasks to assist in the exploration and interpretation of large datasets. Since users may often be unfamiliar with the exact contents of a dataset, clustering can provide a means of introducing some form of organisation to the data, which can also serve to highlight significant patterns and trends. Cluster analysis methods have recently become an important part of commercial and industrial applications for mining data in a variety of domains. In the past, these methods have also been employed to facilitate the discovery of knowledge from large collections of unstructured text. Renewed interest in document clustering has been prompted by the exponential growth in the size of digital document collections, including web pages, e-mail messages and news articles. Another motivating factor has been the increased availability of computing resources, which has encouraged researchers to reconsider the application of machine learning methods to larger corpora. A variety of techniques for generating and evaluating clusterings of text data have been proposed in the literature, which differ significantly in terms of their theoretical foundations and practical implementation. A significant obstacle for researchers interested in harnessing this work is the absence of a comprehensive framework for comparing and extending these techniques. In this thesis, we introduce the Text Clustering Toolkit (TCT), a state-of-the-art framework supporting the development of applications for unsupervised text mining tasks. The toolkit covers all phases of the cluster analysis process, from the preprocessing of raw documents to the interpretation of a final clustering solution. As well as allowing researchers to evaluate popular learning algorithms, TCT also provides a flexible test-bed for the design and the development of novel clustering procedures. The primary focus of a significant body of research in document clustering has been concerned with the production of solutions that are "accurate" in the sense that they succeed in revealing the underlying structure of a dataset. This thesis proposes a selection of novel clustering algorithms, which frequently succeed in accurately identifying the natural trends and groups in document collections. We also describe new strategies to improve the accuracy afforded by existing algorithms, such as those based on kernel learning. A secondary objective, which is frequently overlooked in this area, is the provision of information to help a user interpret the output of an analysis procedure. To support the extraction of knowledge from clustering solutions, techniques are described for producing summary information, in the form of human-interpretable cluster labels. The increase in computing power available to researchers has opened up many new possibilities, such as the study of methods that involve aggregating information obtained from multiple clusterings. This information can often provide additional insight regarding the group structures in a dataset. However, due to the exceptionally large size and highdimensional nature of real-world document collections, the computational cost of applying aggregation methods to text data will generally be prohibitive. To address this scalability problem, we introduce novel techniques for efficiently generating and combining a diverse collection of clusterings to produce more accurate document clustering solutions. A particularly problematic aspect of many common unsupervised learning procedures relates to the selection of key algorithm parameters, which can greatly dictate the success of the procedure. To this end, we explore ways in which the aggregation of information derived from a large collection of clusterings can provide us with clues about the validity of a clustering model. We devote particular attention to the estimation of the number of natural groups or topics in a text corpus, which represents a fundamental issue when employing well-known document clustering algorithms.},
annote = {        From Duplicate 2 (                   A State-of-the-Art Toolkit for Document Clustering                 - Greene, Derek )
                
        
        
      },
author = {Greene, Derek},
booktitle = {Philosophy},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//A State-of-the-Art Toolkit for Document Clustering - 2007 - Greene.pdf:pdf},
keywords = {clustering},
month = oct,
number = {March},
school = {Trinity College Dublin},
title = {{A State-of-the-Art Toolkit for Document Clustering}},
year = {2007}
}
@inproceedings{Zhu1999,
author = {Zhu, Jun and Yang, Qiang},
booktitle = {International Joint Conference on Artificial Intelligence},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Remembering to add competence-preserving case-addition policies for case-base maintenance - 1999 - Zhu, Yang.pdf:pdf},
pages = {234--241},
publisher = {Citeseer},
title = {{Remembering to add: competence-preserving case-addition policies for case-base maintenance}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.48.2713\&amp;rep=rep1\&amp;type=pdf},
volume = {16},
year = {1999}
}
@misc{prog:git,
title = {{Git}},
url = {http://git-scm.com/},
year = {2005}
}
@incollection{Smyth1998,
annote = {        From Duplicate 1 (                           Modelling the competence of case-bases                         - Smyth, Barry; McKenna, Elizabeth )
                
10.1007/BFb0056334
        
      },
author = {Smyth, Barry and McKenna, Elizabeth},
booktitle = {Advances in Case-Based Reasoning},
editor = {Smyth, Barry and Cunningham, P\'{a}draig},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Modelling the competence of case-bases - 1998 - Smyth, McKenna.pdf:pdf},
isbn = {978-3-540-64990-8},
pages = {208--220},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Modelling the competence of case-bases}},
url = {http://dx.doi.org/10.1007/BFb0056334},
volume = {1488},
year = {1998}
}
@misc{prog:aptana,
title = {{Aptana}},
url = {http://aptana.com/}
}
@article{Cunningham2009,
author = {Cunningham, P.},
doi = {10.1109/TKDE.2008.227},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//A Taxonomy of Similarity Mechanisms for Case-Based Reasoning - 2009 - Cunningham.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = nov,
number = {11},
pages = {1532--1543},
title = {{A Taxonomy of Similarity Mechanisms for Case-Based Reasoning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4674351},
volume = {21},
year = {2009}
}
@misc{data:hepatitis,
title = {{Hepatitis Domain}},
url = {http://archive.ics.uci.edu/ml/machine-learning-databases/hepatitis/}
}
@article{Rashidi2011,
author = {Rashidi, Parisa and Cook, Diane J},
isbn = {9781450308137},
journal = {Human Factors},
keywords = {active learning,machine learning},
pages = {904--912},
title = {{Ask Me Better Questions : Active Learning Queries Based on Rule Induction}},
year = {2011}
}
@inproceedings{Hu2009,
author = {Hu, Rong and Delany, Sarah Jane and MacNamee, Brian},
booktitle = {Proceedings of the UKDS Workshop at 8th International Conference on Case-based Reasoning (ICCBR 09)},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Sampling with confidence Using k-nn confidence measures in active learning - 2009 - Hu, Delany, MacNamee.pdf:pdf},
pages = {181--192},
title = {{Sampling with confidence: Using k-nn confidence measures in active learning}},
url = {http://arrow.dit.ie/cgi/viewcontent.cgi?article=1050\&amp;context=scschcomcon},
year = {2009}
}
@article{Cebron2007,
author = {Cebron, Nicolas and Berthold, Michael R},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//An Adaptive Multi Objective Selection Strategy for Active Learning An Adaptive Multi Objective Selection Strategy for Active Learning Technical Report - 2007 - Cebron, Berthold.pdf:pdf},
title = {{An Adaptive Multi Objective Selection Strategy for Active Learning An Adaptive Multi Objective Selection Strategy for Active Learning Technical Report}},
year = {2007}
}
@misc{prog:natbib,
title = {natbib},
url = {http://www.ctan.org/pkg/natbib}
}
@incollection{Delany2009,
annote = {        From Duplicate 1 (                           The Good, the Bad and the Incorrectly Classified: Profiling Cases for Case-Base Editing                         - Delany, Sarah )
                
10.1007/978-3-642-02998-1\_11
        
      },
author = {Delany, Sarah},
booktitle = {Case-Based Reasoning Research and Development},
editor = {McGinty, Lorraine and Wilson, David},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/The Good, the Bad and the Incorrectly Classified Profiling Cases for Case-Base Editing - 2009 - Delany.pdf:pdf},
isbn = {978-3-642-02997-4},
pages = {135--149},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{The Good, the Bad and the Incorrectly Classified: Profiling Cases for Case-Base Editing}},
url = {http://dx.doi.org/10.1007/978-3-642-02998-1\_11},
volume = {5650},
year = {2009}
}
@inproceedings{Donmez2007,
abstract = {Active Learning methods rely on static strategies for sampling unlabeled point(s). These strategies range from uncertainty sampling and density estimation to multi-factor methods with learn-once-use-always model parameters. This paper proposes a dynamic approach, called DUAL, where the strategy selection parameters are adaptively updated based on estimated future residual error reduction after each actively sampled point. The objective of dual is to outperform static strategies over a large operating range: from very few to very many labeled points. Empirical results over six datasets demonstrate that DUAL outperforms several state-of-the-art methods on most datasets.},
author = {Donmez, Pinar and Carbonell, Jaime G and Bennett, Paul N},
booktitle = {Machine Learning ECML 2007},
doi = {10.1007/978-3-540-74958-5\_14},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Dual strategy active learning - 2007 - Donmez, Carbonell, Bennett.pdf:pdf},
isbn = {9783540749578},
pages = {116--127},
publisher = {Springer-Verlag},
series = {ECML '07},
title = {{Dual strategy active learning}},
url = {http://www.springerlink.com/index/325n432605r42282.pdf},
year = {2007}
}
@misc{data:Talk,
title = {talk.religion.misc vs alt.atheism},
url = {http://people.csail.mit.edu/jrennie/20Newsgroups/}
}
@misc{web:kfolddemo,
title = {{K-Fold Cross Validation Demonstration}},
url = {http://animation.yihui.name/dmml:k-fold\_cross-validation}
}
@article{Ontanon2003,
abstract = {Empirical experiments have shown that storing every case does not automatically improve the accuracy of a CBR system. Therefore, several retain policies have been proposed in order to select which cases to retain. However, all the research done in case retention strategies is done in centralized CBR systems. We focus on multiagent CBR systems, where each agent has a local case base, and where each agent can interact with other agents in the system to solve problems in a collaborative way. We propose several case retention strategies that directly deal with the issue of being in a multiagent CBR system. Those case retention strategies combine ideas from the CBR case retain strategies and from the active learning techniques. Empirical results show that strategies that use collaboration with other agents outperform those strategies where the agents work in isolation. We present experiments in two different scenarios, the first one allowing multiple copies of one case and the second one only allowing one copy of each case. Although it may seem counterintuitive, we show and explain why not allowing multiple copies of each case achieves better results.},
author = {Onta\~{n}\'{o}n, S and Plaza, Enric},
editor = {Bridge, D and Ashley, K},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Collaborative Case Retention Strategies for CBR Agents - 2003 - Onta\~{n}\'{o}n, Plaza.pdf:pdf},
journal = {CaseBased Reasoning Research and Development Proceedings of the Fifth International Conference on CaseBased Reasoning ICCBR03},
pages = {392--406},
publisher = {Springer-Verlag},
title = {{Collaborative Case Retention Strategies for CBR Agents}},
url = {http://dblp.uni-trier.de/db/conf/iccbr/iccbr2003.html\#OntanonP03},
volume = {2689},
year = {2003}
}
@misc{data:dermatology,
title = {{Dermatology Database}},
url = {http://archive.ics.uci.edu/ml/machine-learning-databases/dermatology/}
}
@article{Smyth1995,
author = {Smyth, Barry},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Remembering To Forget A Competence-Preserving Case Deletion Policy for Case-Based Reasoning Systems - Unknown - Smyth.pdf:pdf},
journal = {Proceedings of the 14th International Joint Conference},
title = {{Remembering To Forget A Competence-Preserving Case Deletion Policy for Case-Based Reasoning Systems}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Remembering+To+Forget+A+Competence-Preserving+Case+Deletion+Policy+for+Case-Based+Reasoning+Systems\#3}
}
@incollection{springerlink:10.1007/11536406_16,
annote = {10.1007/11536406\_16},
author = {Delany, Sarah and Cunningham, P\'{a}draig and Doyle, D\'{o}nal and Zamolotskikh, Anton},
booktitle = {Case-Based Reasoning Research and Development},
editor = {Mu\~{n}oz-\'{A}vila, H\'{e}ctor and Ricci, Francesco},
isbn = {978-3-540-28174-0},
pages = {177--190},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Generating Estimates of Classification Confidence for a Case-Based Spam Filter}},
url = {http://dx.doi.org/10.1007/11536406\_16},
volume = {3620},
year = {2005}
}
@misc{prog:dia,
title = {{Dia}},
url = {http://dia-installer.de/},
year = {2001}
}
@misc{prog:protocolbuffers,
title = {{Protocol Buffers}},
url = {http://code.google.com/apis/protocolbuffers/}
}
@article{Delany2005,
author = {Delany, S.J. and Cunningham, P. and Doyle, D. and Zamolotskikh, A.},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Generating estimates of classification confidence for a case-based spam filter - 2005 - Delany et al.pdf:pdf},
journal = {Case-Based Reasoning Research and Development},
pages = {177--190},
publisher = {Springer},
title = {{Generating estimates of classification confidence for a case-based spam filter}},
url = {http://www.springerlink.com/index/79t1wwgpjj8q2vpq.pdf},
year = {2005}
}
@article{Zhu2008a,
address = {Morristown, NJ, USA},
author = {Zhu, Jingbo and Wang, Huizhen and Hovy, Eduard},
doi = {10.3115/1599081.1599223},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Multi-criteria-based strategy to stop active learning for data annotation - 2008 - Zhu, Wang, Hovy.pdf:pdf},
isbn = {9781905593446},
journal = {Proceedings of the 22nd International Conference on Computational Linguistics - COLING '08},
number = {August},
pages = {1129--1136},
publisher = {Association for Computational Linguistics},
title = {{Multi-criteria-based strategy to stop active learning for data annotation}},
url = {http://portal.acm.org/citation.cfm?doid=1599081.1599223},
volume = {1},
year = {2008}
}
@article{Donmez2010,
author = {Donmez, Pinar and Carbonell, Jaime G},
journal = {Machine Learning},
pages = {97--120},
title = {{From Active to Proactive Learning Methods}},
year = {2010}
}
@misc{prog:unxutils,
title = {{GNU utilities for Win32}},
url = {http://unxutils.sourceforge.net/}
}
@article{RoySamplingEstimation2001,
author = {Roy, Nicholas},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Toward Optimal Active Learning through Sampling Estimation of Error Reduction - 2001 - Roy, McCallum.pdf:pdf},
journal = {LEARNING-INTERNATIONAL WORKSHOP THEN},
title = {{Toward optimal active learning through sampling estimation of error reduction}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.9963\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@misc{prog:pdfrider,
title = {{PDF Rider}},
url = {http://pdfrider.codeplex.com},
year = {2009}
}
@misc{prog:latexcodec,
title = {latexcodec},
url = {http://pypi.python.org/pypi/latexcodec},
year = {2011}
}
@article{Guo2007,
author = {Guo, Yuhong and Schuurmans, Dale},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Discriminative batch mode active learning - 2007 - Guo, Schuurmans.pdf:pdf},
journal = {Advances in Neural Information Processing Systems (NIPS)},
pages = {593--600},
publisher = {Citeseer},
title = {{Discriminative batch mode active learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.8661\&amp;rep=rep1\&amp;type=pdf},
year = {2007}
}
@misc{prog:bpython,
title = {bpython},
url = {http://bpython-interpreter.org/home/}
}
@article{Nguyen2004,
address = {New York, New York, USA},
author = {Nguyen, Hieu T. and Smeulders, Arnold},
doi = {10.1145/1015330.1015349},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Active learning using pre-clustering - 2004 - Nguyen, Smeulders.pdf:pdf},
isbn = {1581138285},
journal = {Twenty-first international conference on Machine learning - ICML '04},
pages = {79},
publisher = {ACM Press},
title = {{Active learning using pre-clustering}},
url = {http://portal.acm.org/citation.cfm?doid=1015330.1015349},
year = {2004}
}
@article{Hospedales,
author = {Hospedales, Timothy and Gong, Shaogang},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Finding Rare Classes Adapting Generative and Discriminative Models in Active Learning - 2011 - Hospedales, Gong.pdf:pdf},
journal = {Advances in Knowledge Discovery and},
title = {{Finding Rare Classes: Adapting Generative and Discriminative Models in Active Learning}},
url = {http://www.springerlink.com/index/3R0581PT46325607.pdf},
year = {2011}
}
@article{Yu2010,
abstract = {As many databases have been brought online, data retrievalfinding relevant data from large databaseshas become a nontrivial task. A feedback-based data retrieval system was proposed to provide user with an intuitive way for expressing their preferences in queries. The system iteratively receives a partial ordering on a sample of data from the user, learns a ranking function, and returns highly ranked results according to the function. An important issue in such retrieval systems is minimizing the number of iterations or the amount of feedback to learn an accurate ranking function. This paper proposes selective sampling (or active learning) techniques for RankSVM that can be used in the retrieval systems. The proposed techniques minimizes the amount of user interaction to learn an accurate ranking function thus facilitates users formulating a preference query in the data retrieval system.},
author = {Yu, Hwanjo},
doi = {10.1007/s10618-010-0168-8},
isbn = {1061801001688},
issn = {13845810},
journal = {Data Mining and Knowledge Discovery},
number = {1-2},
pages = {1--30},
publisher = {Springer Netherlands},
title = {{Selective sampling techniques for feedback-based data retrieval}},
url = {http://www.springerlink.com/content/x300570826l0t488/},
volume = {22},
year = {2010}
}
@misc{prog:aptana,
title = {{Aptana}},
url = {http://aptana.com/},
year = {2006}
}
@misc{prog:texstudio,
title = {{TexStudio}},
url = {http://texstudio.sourceforge.net/}
}
@misc{prog:graphviz,
title = {{Graphviz}},
url = {http://www.graphviz.org/},
year = {2001}
}
@article{Hu2008,
author = {Hu, R and Namee, B Mac and Delany, SJ},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Sweetening the dataset Using active learning to label unlabelled datasets - 2008 - Hu, Namee, Delany.pdf:pdf},
journal = {Proceedings of the the 19th Irish},
title = {{Sweetening the dataset: Using active learning to label unlabelled datasets}},
url = {http://arrow.dit.ie/cgi/viewcontent.cgi?article=1019\&context=scschcomcon},
year = {2008}
}
@article{RoyMonteCarlo2001,
author = {Roy, Nicholas},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Toward optimal active learning through monte carlo estimation of error reduction - 2001 - Roy.pdf:pdf},
journal = {ICML, Williamstown},
title = {{Toward optimal active learning through monte carlo estimation of error reduction}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.6296\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@misc{data:wine,
title = {{Wine recognition data}},
url = {http://archive.ics.uci.edu/ml/machine-learning-databases/wine/}
}
@phdthesis{Greene2007,
author = {Greene, Derek},
booktitle = {Philosophy},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//A State-of-the-Art Toolkit for Document Clustering - 2007 - Greene.pdf:pdf},
number = {March},
title = {{A State-of-the-Art Toolkit for Document Clustering}},
year = {2007}
}
@misc{prog:orange,
title = {{Orange}},
url = {http://orange.biolab.si/},
year = {2005}
}
@inproceedings{Bondu2010,
author = {Bondu, A and Lemaire, V and Boull\'{e}, M},
booktitle = {Computational Intelligence},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Exploration vs . exploitation in active learning a Bayesian approach - 2010 - Bondu, Lemaire, Boull\'{e}.pdf:pdf},
pages = {18--23},
publisher = {IEEE},
title = {{Exploration vs . exploitation in active learning : a Bayesian approach}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5596815},
year = {2010}
}
@inproceedings{Sun2010,
author = {Sun, L L and Wang, X Z},
booktitle = {Machine Learning and Cybernetics ICMLC 2010 International Conference on},
isbn = {9781424465279},
keywords = {active learning,machine learning,query strategy},
number = {July},
pages = {161--166},
publisher = {IEEE},
title = {{A survey on active learning strategy}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5581075},
volume = {1},
year = {2010}
}
@article{Tomanek2011,
author = {Tomanek, Katrin and Morik, Katharina},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Inspecting Sample Reusability for Active Learning - 2011 - Tomanek, Morik.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {active learning,covariate shift,sample selection bias,uncertainty sampling},
pages = {169--181},
title = {{Inspecting Sample Reusability for Active Learning}},
volume = {16},
year = {2011}
}
@techreport{Settles2010,
annote = {        From Duplicate 2 (                   Active Learning Literature Survey                 - Settles, Burr )
                
        
        
      },
author = {Settles, Burr},
booktitle = {Sciences-New York},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Active Learning Literature Survey - 2009 - Settles.pdf:pdf},
institution = {University of Wisconsin--Madison},
number = {1648},
title = {{Active Learning Literature Survey}},
type = {Computer Sciences Technical Report},
year = {2009}
}
@article{Jorge2009,
author = {Jorge, A and Escudeiro, N F},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Efficient coverage of case space with active learning - 2009 - Jorge, Escudeiro.pdf:pdf},
journal = {Progress in Artificial Intelligence},
pages = {411--422},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Efficient coverage of case space with active learning}},
url = {http://www.springerlink.com/index/96244562U41762QP.pdf},
volume = {5816},
year = {2009}
}
@misc{prog:virtualbox,
title = {{VirtualBox}},
url = {https://www.virtualbox.org/},
year = {2007}
}
@article{King2009,
abstract = {The basis of science is the hypothetico-deductive method and the recording of experiments in sufficient detail to enable reproducibility. We report the development of Robot Scientist "Adam," which advances the automation of both. Adam has autonomously generated functional genomics hypotheses about the yeast Saccharomyces cerevisiae and experimentally tested these hypotheses by using laboratory automation. We have confirmed Adam's conclusions through manual experiments. To describe Adam's research, we have developed an ontology and logical language. The resulting formalization involves over 10,000 different research units in a nested treelike structure, 10 levels deep, that relates the 6.6 million biomass measurements to their logical description. This formalization describes how a machine contributed to scientific knowledge.},
author = {King, Ross D and Rowland, Jem and Oliver, Stephen G and Young, Michael and Aubrey, Wayne and Byrne, Emma and Liakata, Maria and Markham, Magdalena and Pir, Pinar and Soldatova, Larisa N and Sparkes, Andrew and Whelan, Kenneth E and Clare, Amanda},
doi = {10.1126/science.1165620},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/The automation of science. - 2009 - King et al.pdf:pdf},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Artificial Intelligence,Automation,Computational Biology,Computers,Enzymes,Enzymes: genetics,Genes, Fungal,Genomics,Programming Languages,Robotics,Saccharomyces cerevisiae,Saccharomyces cerevisiae: enzymology,Saccharomyces cerevisiae: genetics,Saccharomyces cerevisiae: growth \& development,Saccharomyces cerevisiae: metabolism,Software},
month = apr,
number = {5923},
pages = {85--9},
pmid = {19342587},
title = {{The automation of science.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19342587},
volume = {324},
year = {2009}
}
@misc{prog:datatool,
title = {{Datatool}},
url = {http://www.ctan.org/pkg/datatool}
}
@misc{data:heartdisease,
title = {{Heart Disease Databases}},
url = {http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/}
}
@misc{web:knntut,
title = {{Knn Tutorial}},
url = {http://paul.luminos.nl/download/document/knn.pdf}
}
@incollection{Delany2009,
annote = {        From Duplicate 1 (                   The Good, the Bad and the Incorrectly Classified: Profiling Cases for Case-Base Editing                 - Delany, Sarah )
                
10.1007/978-3-642-02998-1\_11
        
        From Duplicate 2 (                   The Good, the Bad and the Incorrectly Classified: Profiling Cases for Case-Base Editing                 - Delany, Sarah )
                
        From Duplicate 1 (                           The Good, the Bad and the Incorrectly Classified: Profiling Cases for Case-Base Editing                         - Delany, Sarah )
                
10.1007/978-3-642-02998-1\_11
        
        
        
      },
author = {Delany, Sarah},
booktitle = {Case-Based Reasoning Research and Development},
editor = {McGinty, Lorraine and Wilson, David},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/The Good, the Bad and the Incorrectly Classified Profiling Cases for Case-Base Editing - 2009 - Delany.pdf:pdf},
isbn = {978-3-642-02997-4},
pages = {135--149},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{The Good, the Bad and the Incorrectly Classified: Profiling Cases for Case-Base Editing}},
url = {http://dx.doi.org/10.1007/978-3-642-02998-1\_11},
volume = {5650},
year = {2009}
}
@inproceedings{Donmez2008,
author = {Donmez, Pinar and Carbonell, Jaime},
booktitle = {Proceedings of the 10th International Symposium on Artificial Intelligence and Mathematics, Florida, 2008},
title = {{Paired-Sampling in Density-Sensitive Active Learning}},
url = {http://repository.cmu.edu/compsci/268},
year = {2008}
}
@misc{prog:briss,
title = {briss},
url = {http://sourceforge.net/projects/briss/},
year = {2010}
}
@misc{web:projectsourcecode,
title = {{Project Source Code}},
url = {https://github.com/Epinoch/FYP}
}
@inproceedings{Roy2001,
abstract = {This paper presents an active learning method that directly optimizes expected future error. This is in contrast to many other popular techniques that instead aim to reduce version space size. These other methods are popular because for many learning models, closed form calculation of the expected future error is intractable. Our approach is made feasible by taking a sampling approach to estimating the expected reduction in error due to the labeling of a query. In experimental results on two real-world data sets we reach high accuracy very quickly, sometimes with four times fewer labeled examples than competing methods.},
author = {Roy, Nick and McCallum, Andrew},
booktitle = {Proc 18th International Conf on Machine Learning},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Toward Optimal Active Learning through Sampling Estimation of Error Reduction - 2001 - Roy, McCallum.pdf:pdf},
isbn = {1558607781},
pages = {441--448},
publisher = {Citeseer},
title = {{Toward Optimal Active Learning through Sampling Estimation of Error Reduction}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.9963\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@misc{data:haberman,
title = {{Haberman's Survival Data}},
url = {http://archive.ics.uci.edu/ml/machine-learning-databases/haberman/}
}
@article{Kang2004,
author = {Kang, Jaeho and Ryu, Kwang Ryel and Kwon, Hyuk-Chul},
journal = {Training},
pages = {384--388},
title = {{Using Cluster-Based Sampling to Select Initial Training Set for Active Learning}},
year = {2004}
}
@article{Beygelzimer2008,
abstract = {We present a practical and statistically consistent scheme for actively learning binary classifiers under general loss functions. Our algorithm uses importance weighting to correct sampling bias, and by controlling the variance, we are able to give rigorous label complexity bounds for the learning process. Experiments on passively labeled data show that this approach reduces the label complexity required to achieve good predictive performance on many learning problems.},
author = {Beygelzimer, Alina and Dasgupta, Sanjoy and Langford, John},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Importance Weighted Active Learning - 2008 - Beygelzimer, Dasgupta, Langford.pdf:pdf},
journal = {Proceedings of the 26th Annual International Conference on Machine Learning ICML 09},
number = {ii},
pages = {1--8},
publisher = {ACM Press},
series = {ICML '09},
title = {{Importance Weighted Active Learning}},
url = {http://arxiv.org/abs/0812.4952},
volume = {abs/0812.4},
year = {2008}
}
@article{Cebron2007,
author = {Cebron, Nicolas and Berthold, Michael R},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//An Adaptive Multi Objective Selection Strategy for Active Learning An Adaptive Multi Objective Selection Strategy for Active Learning Technical Report - 2007 - Cebron, Berthold.pdf:pdf},
title = {{An Adaptive Multi Objective Selection Strategy for Active Learning An Adaptive Multi Objective Selection Strategy for Active Learning Technical Report}},
year = {2007}
}
@incollection{springerlink:10.1007/978-3-642-14274-1_13,
annote = {        From Duplicate 1 (                           EGAL: Exploration Guided Active Learning for TCBR                         - Hu, Rong; Jane Delany, Sarah; Mac Namee, Brian )
                
        From Duplicate 1 (                           EGAL: Exploration Guided Active Learning for TCBR                         - Hu, Rong; Jane Delany, Sarah; Mac Namee, Brian )
                
10.1007/978-3-642-14274-1\_13
        
        From Duplicate 2 (                           EGAL: Exploration Guided Active Learning for TCBR                         - Hu, Rong; Jane Delany, Sarah; Mac Namee, Brian )
                
        From Duplicate 1 (                           EGAL: Exploration Guided Active Learning for TCBR                         - Hu, Rong; Jane Delany, Sarah; Mac Namee, Brian )
                
10.1007/978-3-642-14274-1\_13
        
        
        
        
        
        From Duplicate 2 (                           EGAL: Exploration Guided Active Learning for TCBR                         - Hu, Rong; Jane Delany, Sarah; Mac Namee, Brian )
                
10.1007/978-3-642-14274-1\_13
        
      },
author = {Hu, Rong and {Jane Delany}, Sarah and {Mac Namee}, Brian},
booktitle = {Case-Based Reasoning. Research and Development},
editor = {Bichindaritz, Isabelle and Montani, Stefania},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/EGAL Exploration Guided Active Learning for TCBR - 2010 - Hu, Jane Delany, Mac Namee.pdf:pdf},
isbn = {978-3-642-14273-4},
pages = {156--170},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{EGAL: Exploration Guided Active Learning for TCBR}},
url = {http://dx.doi.org/10.1007/978-3-642-14274-1\_13},
volume = {6176},
year = {2010}
}
@article{Hu2008,
author = {Hu, R and Namee, B Mac and Delany, SJ},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Sweetening the dataset Using active learning to label unlabelled datasets - 2008 - Hu, Namee, Delany.pdf:pdf},
journal = {Proceedings of the the 19th Irish},
title = {{Sweetening the dataset: Using active learning to label unlabelled datasets}},
url = {http://arrow.dit.ie/cgi/viewcontent.cgi?article=1019\&context=scschcomcon},
year = {2008}
}
@inproceedings{Massie2005,
author = {Massie, Stewart and Craw, Susan and Wiratunga, Nirmalie},
booktitle = {PROCEEDINGS OF THE NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Complexity-Guided Case Discovery for Case Based Reasoning Related Work in Case Discovery Complexity-Guided Case Discovery - 2003 - Massie, Craw, Wiratunga.pdf:pdf},
number = {1},
pages = {216},
publisher = {Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999},
title = {{Complexity-guided case discovery for case based reasoning}},
url = {http://www.aaai.org/Papers/AAAI/2005/AAAI05-035.pdf},
volume = {20},
year = {2005}
}
@inproceedings{Ng2007,
abstract = {Owing to the growth of Internet and computer technology, pattern recognition for large-scale datasets has become one of the hot research topics. The major challenges are to reduce the human efforts involved and to improve the efficiency. Traditional passive learning methods require labeling of all training samples may not be feasible in large-scale recognition problems because of the requirement of large-scale class labeling for the huge number of training samples. In the literatures, there are many studies on active learning methods, which does not require all training samples to be labeled and it selects training samples for labeling based on the knowledge of the current classifier. In this paper, we present an active learning method using localized generalization error of candidate sample as selection criterion. Our method uses the generalization error of candidate sample, so theoretically it should have a better performance than other methods. From the experiment results, our method outperforms other methods in both yielding higher prediction accuracy on testing dataset and selecting fewer training samples. Furthermore, we propose a heuristics improvement based on the Q -neighborhood idea of the localized generalization error model to reduce the number of samples being selected and the computational time.},
author = {Ng, Wing W. Y. and Sun, Binbin and Yeung, Daniel S.},
booktitle = {2007 IEEE International Conference on Systems, Man and Cybernetics},
doi = {10.1109/ICSMC.2007.4413940},
isbn = {978-1-4244-0990-7},
pages = {3588--3593},
publisher = {IEEE},
title = {{Heuristic improvement for active learning using localized generalization error as selection criterion}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4413940},
year = {2007}
}
@article{Yu2010,
abstract = {As many databases have been brought online, data retrievalfinding relevant data from large databaseshas become a nontrivial task. A feedback-based data retrieval system was proposed to provide user with an intuitive way for expressing their preferences in queries. The system iteratively receives a partial ordering on a sample of data from the user, learns a ranking function, and returns highly ranked results according to the function. An important issue in such retrieval systems is minimizing the number of iterations or the amount of feedback to learn an accurate ranking function. This paper proposes selective sampling (or active learning) techniques for RankSVM that can be used in the retrieval systems. The proposed techniques minimizes the amount of user interaction to learn an accurate ranking function thus facilitates users formulating a preference query in the data retrieval system.},
author = {Yu, Hwanjo},
doi = {10.1007/s10618-010-0168-8},
isbn = {1061801001688},
issn = {13845810},
journal = {Data Mining and Knowledge Discovery},
number = {1-2},
pages = {1--30},
publisher = {Springer Netherlands},
title = {{Selective sampling techniques for feedback-based data retrieval}},
url = {http://www.springerlink.com/content/x300570826l0t488/},
volume = {22},
year = {2010}
}
@article{Lan2011,
author = {Lan, Liang and Shi, H and Wang, Zhuang and Vucetic, S},
journal = {jmlrcsailmitedu},
keywords = {active learning,clustering,ensemble classifiers,feature filter,parzen window},
pages = {99--112},
title = {{An Active Learning Algorithm Based on Parzen Window Classification}},
url = {http://jmlr.csail.mit.edu/proceedings/papers/v16/lan11a/lan11a.pdf},
volume = {16},
year = {2011}
}
@article{Hu2011,
author = {Hu, Rong},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Active Learning for Text Classification - 2011 - Hu.pdf:pdf},
title = {{Active Learning for Text Classification}},
year = {2011}
}
@article{Tomanek2011,
author = {Tomanek, Katrin and Morik, Katharina},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Inspecting Sample Reusability for Active Learning - 2011 - Tomanek, Morik.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {active learning,covariate shift,sample selection bias,uncertainty sampling},
pages = {169--181},
title = {{Inspecting Sample Reusability for Active Learning}},
volume = {16},
year = {2011}
}
@article{Kang2004,
author = {Kang, Jaeho and Ryu, Kwang Ryel and Kwon, Hyuk-Chul},
journal = {Training},
pages = {384--388},
title = {{Using Cluster-Based Sampling to Select Initial Training Set for Active Learning}},
year = {2004}
}
@article{Guo2007,
author = {Guo, Yuhong and Schuurmans, Dale},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Discriminative batch mode active learning - 2007 - Guo, Schuurmans.pdf:pdf},
journal = {Advances in Neural Information Processing Systems (NIPS)},
pages = {593--600},
publisher = {Citeseer},
title = {{Discriminative batch mode active learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.8661\&amp;rep=rep1\&amp;type=pdf},
year = {2007}
}
@inproceedings{Guo2007a,
abstract = {An "active learning system" will sequentially decide which unlabeled instance to label, with the goal of efficiently gathering the information necessary to produce a good classifier. Some such systems greedily select the next instance based only on properties of that instance and the few currently labeled points - e.g., selecting the one closest to the current classification boundary. Unfortunately, these approaches ignore the valuable information contained in the other unlabeled instances, which can help identify a good classifier much faster. For the previous approaches that do exploit this unlabeled data, this information is mostly used in a conservative way. One common property of the approaches in the literature is that the active learner sticks to one single query selection criterion in the whole process. We propose a system, MM+M, that selects the query instance that is able to provide the maximum conditional mutual information about the labels of the unlabeled instances, given the labeled data, in an optimistic way. This approach implicitly exploits the discriminative partition information contained in the unlabeled data. Instead of using one selection criterion, MM+M also employs a simple on-line method that changes its selection rule when it encounters an "unexpected label". Our empirical results demonstrate that this new approach works effectively.},
author = {Guo, Yuhong and Greiner, Russ},
booktitle = {IJCAI},
keywords = {learning},
pages = {823--829},
title = {{Optimistic active learning using mutual information}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Optimistic+Active+Learning+using+Mutual+Information\#0},
volume = {7},
year = {2007}
}
@inproceedings{Bondu2010,
author = {Bondu, A and Lemaire, V and Boull\'{e}, M},
booktitle = {Computational Intelligence},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Exploration vs . exploitation in active learning a Bayesian approach - 2010 - Bondu, Lemaire, Boull\'{e}.pdf:pdf},
pages = {18--23},
publisher = {IEEE},
title = {{Exploration vs . exploitation in active learning : a Bayesian approach}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5596815},
year = {2010}
}
@inproceedings{Abe1998,
author = {Abe, N. and Mamitsuka, H.},
booktitle = {Proceedings of the Fifteenth International Conference on Machine Learning},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Query learning strategies using boosting and bagging - 1998 - Abe, Mamitsuka.pdf:pdf},
title = {{Query learning strategies using boosting and bagging}},
url = {http://webia.lip6.fr/~amini/RelatedWorks/Abe98.pdf},
volume = {388},
year = {1998}
}
@inproceedings{Hu2009,
author = {Hu, Rong and Delany, Sarah Jane and MacNamee, Brian},
booktitle = {Proceedings of the UKDS Workshop at 8th International Conference on Case-based Reasoning (ICCBR 09)},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Sampling with confidence Using k-nn confidence measures in active learning - 2009 - Hu, Delany, MacNamee.pdf:pdf},
pages = {181--192},
title = {{Sampling with confidence: Using k-nn confidence measures in active learning}},
url = {http://arrow.dit.ie/cgi/viewcontent.cgi?article=1050\&amp;context=scschcomcon},
year = {2009}
}
@inproceedings{Donmez2007,
abstract = {Active Learning methods rely on static strategies for sampling unlabeled point(s). These strategies range from uncertainty sampling and density estimation to multi-factor methods with learn-once-use-always model parameters. This paper proposes a dynamic approach, called DUAL, where the strategy selection parameters are adaptively updated based on estimated future residual error reduction after each actively sampled point. The objective of dual is to outperform static strategies over a large operating range: from very few to very many labeled points. Empirical results over six datasets demonstrate that DUAL outperforms several state-of-the-art methods on most datasets.},
author = {Donmez, Pinar and Carbonell, Jaime G and Bennett, Paul N},
booktitle = {Machine Learning ECML 2007},
doi = {10.1007/978-3-540-74958-5\_14},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Dual strategy active learning - 2007 - Donmez, Carbonell, Bennett.pdf:pdf},
isbn = {9783540749578},
pages = {116--127},
publisher = {Springer-Verlag},
series = {ECML '07},
title = {{Dual strategy active learning}},
url = {http://www.springerlink.com/index/325n432605r42282.pdf},
year = {2007}
}
@article{Shen2004,
address = {Morristown, NJ, USA},
author = {Shen, Dan and Zhang, Jie and Su, Jian and Zhou, Guodong and Tan, Chew-Lim},
doi = {10.3115/1218955.1219030},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Multi-criteria-based active learning for named entity recognition - 2004 - Shen et al.pdf:pdf},
journal = {Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics - ACL '04},
pages = {589--es},
publisher = {Association for Computational Linguistics},
title = {{Multi-criteria-based active learning for named entity recognition}},
url = {http://portal.acm.org/citation.cfm?doid=1218955.1219030},
year = {2004}
}
@article{Zhao2008,
author = {Zhao, Wentao and Long, Jun and Zhu, En and Liu, Yun},
journal = {Frontiers in Algorithmics},
keywords = {active learning,graph based learning},
number = {x},
pages = {311--322},
publisher = {Springer},
title = {{A Scalable Algorithm for Graph-Based Active}},
url = {http://www.springerlink.com/index/835ml8m5v8028217.pdf},
year = {2008}
}
@article{He,
author = {He, Jingrui},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Nearest-neighbor-based active learning for rare category detection - 2007 - He.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {1--8},
title = {{Nearest-neighbor-based active learning for rare category detection}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.69.1601\&amp;rep=rep1\&amp;type=pdf},
year = {2007}
}
@article{Rashidi2011,
author = {Rashidi, Parisa and Cook, Diane J},
isbn = {9781450308137},
journal = {Human Factors},
keywords = {active learning,machine learning},
pages = {904--912},
title = {{Ask Me Better Questions : Active Learning Queries Based on Rule Induction}},
year = {2011}
}
@article{Xu2007,
author = {Xu, Zuobing and Akella, Ram and Zhang, Yi},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Incorporating diversity and density in active learning for relevance feedback - 2007 - Xu, Akella, Zhang.pdf:pdf},
journal = {Advances in Information Retrieval},
pages = {246--257},
publisher = {Springer},
title = {{Incorporating diversity and density in active learning for relevance feedback}},
url = {http://www.springerlink.com/index/J20663R2R1116141.pdf},
year = {2007}
}
@article{Cebron2008,
abstract = {Classifying large datasets without any a-priori information poses a problem in numerous tasks. Especially in industrial environments, we often encounter diverse measurement devices and sensors that produce huge amounts of data, but we still rely on a human expert to help give the data a meaningful interpretation. As the amount of data that must be manually classified plays a critical role,we need to reduce the number of learning episodes involving human interactions as much as possible. In addition for real world applications it is fundamental to converge in a stable manner to a solution that is close to the optimal solution. We present a new self-controlled exploration/exploitation strategy to select data points to be labeled by a domain expert where the potential of each data point is computed based on a combination of its representativeness and the uncertainty of the classifier. A new Prototype Based Active Learning (PBAC) algorithm for classification is introduced. We compare the results to other active learning approaches on several benchmark datasets.},
author = {Cebron, Nicolas and Berthold, Michael R.},
doi = {10.1007/s10618-008-0115-0},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Active learning for object classification from exploration to exploitation - 2008 - Cebron, Berthold.pdf:pdf},
issn = {13845810},
journal = {Data Mining and Knowledge Discovery},
keywords = {active learning,data mining,exploitation,exploration,prototype classification,subtractive clustering},
month = jul,
number = {2},
pages = {283--299},
title = {{Active learning for object classification: from exploration to exploitation}},
url = {http://www.springerlink.com/index/10.1007/s10618-008-0115-0},
volume = {18},
year = {2008}
}
@article{Lindstrom2010,
author = {Lindstrom, Patrick and Hu, R. and Delany, S.J. and {Mac Namee}, B.},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//SVM Based Active Learning with Exploration - 2010 - Lindstrom et al.pdf:pdf},
journal = {Electrical Engineering},
pages = {1--3},
title = {{SVM Based Active Learning with Exploration}},
url = {http://arrow.dit.ie/cgi/viewcontent.cgi?article=1127\&amp;context=engscheleart},
year = {2010}
}
@article{Zhu2008a,
address = {Morristown, NJ, USA},
author = {Zhu, Jingbo and Wang, Huizhen and Hovy, Eduard},
doi = {10.3115/1599081.1599223},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Multi-criteria-based strategy to stop active learning for data annotation - 2008 - Zhu, Wang, Hovy.pdf:pdf},
isbn = {9781905593446},
journal = {Proceedings of the 22nd International Conference on Computational Linguistics - COLING '08},
number = {August},
pages = {1129--1136},
publisher = {Association for Computational Linguistics},
title = {{Multi-criteria-based strategy to stop active learning for data annotation}},
url = {http://portal.acm.org/citation.cfm?doid=1599081.1599223},
volume = {1},
year = {2008}
}
@article{RoyMonteCarlo2001,
author = {Roy, Nicholas},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Toward optimal active learning through monte carlo estimation of error reduction - 2001 - Roy.pdf:pdf},
journal = {ICML, Williamstown},
title = {{Toward optimal active learning through monte carlo estimation of error reduction}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.6296\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@article{Hu2010,
author = {Hu, Rong and Namee, Brian Mac and Delany, Sarah Jane},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Off to a Good Start Using Clustering to Select the Initial Training Set in Active Learning - 2010 - Hu, Namee, Delany.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {general conference papers},
number = {Flairs},
pages = {26--31},
title = {{Off to a Good Start : Using Clustering to Select the Initial Training Set in Active Learning}},
year = {2010}
}
@article{Jorge2009,
author = {Jorge, A and Escudeiro, N F},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Efficient coverage of case space with active learning - 2009 - Jorge, Escudeiro.pdf:pdf},
journal = {Progress in Artificial Intelligence},
pages = {411--422},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Efficient coverage of case space with active learning}},
url = {http://www.springerlink.com/index/96244562U41762QP.pdf},
volume = {5816},
year = {2009}
}
@inproceedings{Roy2001,
abstract = {This paper presents an active learning method that directly optimizes expected future error. This is in contrast to many other popular techniques that instead aim to reduce version space size. These other methods are popular because for many learning models, closed form calculation of the expected future error is intractable. Our approach is made feasible by taking a sampling approach to estimating the expected reduction in error due to the labeling of a query. In experimental results on two real-world data sets we reach high accuracy very quickly, sometimes with four times fewer labeled examples than competing methods.},
author = {Roy, Nick and McCallum, Andrew},
booktitle = {Proc 18th International Conf on Machine Learning},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Toward Optimal Active Learning through Sampling Estimation of Error Reduction - 2001 - Roy, McCallum.pdf:pdf},
isbn = {1558607781},
pages = {441--448},
publisher = {Citeseer},
title = {{Toward Optimal Active Learning through Sampling Estimation of Error Reduction}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.9963\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@article{Pan2007,
author = {Pan, R and Yang, Q and Pan, S},
doi = {10.1016/j.artint.2007.04.018},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Mining competent case bases for case-based reasoning - 2007 - Pan, Yang, Pan.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {case-base mining,case-based reasoning,competence,kgcm},
month = nov,
number = {16-17},
pages = {1039--1068},
title = {{Mining competent case bases for case-based reasoning}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370207000938},
volume = {171},
year = {2007}
}
@article{Baram2004,
author = {Baram, Yoram and El-Yaniv, R},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Online choice of active learning algorithms - 2004 - Baram, El-Yaniv.pdf:pdf},
journal = {The Journal of Machine Learning},
title = {{Online choice of active learning algorithms}},
url = {http://portal.acm.org/citation.cfm?id=1005342},
year = {2004}
}
@inproceedings{Sun2010,
author = {Sun, L L and Wang, X Z},
booktitle = {Machine Learning and Cybernetics ICMLC 2010 International Conference on},
isbn = {9781424465279},
keywords = {active learning,machine learning,query strategy},
number = {July},
pages = {161--166},
publisher = {IEEE},
title = {{A survey on active learning strategy}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5581075},
volume = {1},
year = {2010}
}
@article{Smyth,
author = {Smyth, Barry},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Remembering To Forget A Competence-Preserving Case Deletion Policy for Case-Based Reasoning Systems - Unknown - Smyth.pdf:pdf},
journal = {Proceedings of the 14th International Joint Conference},
title = {{Remembering To Forget A Competence-Preserving Case Deletion Policy for Case-Based Reasoning Systems}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Remembering+To+Forget+A+Competence-Preserving+Case+Deletion+Policy+for+Case-Based+Reasoning+Systems\#3}
}
@article{Cunningham2009,
author = {Cunningham, P.},
doi = {10.1109/TKDE.2008.227},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//A Taxonomy of Similarity Mechanisms for Case-Based Reasoning - 2009 - Cunningham.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = nov,
number = {11},
pages = {1532--1543},
title = {{A Taxonomy of Similarity Mechanisms for Case-Based Reasoning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4674351},
volume = {21},
year = {2009}
}
@article{Guan2008,
author = {Guan, Donghai and Yuan, Weiwei and Lee, Young-Koo and Gavrilov, Andrey and Lee, Sungyoung},
issn = {1064-1246},
journal = {Journal of Intelligent \& Fuzzy Systems: Applications in Engineering and Technology},
keywords = {Classification,border-based selection,center-based selection,data selection,fuzzy clustering,hybrid selection},
month = dec,
number = {4,5},
pages = {321--334},
title = {{Improving supervised learning performance by using fuzzy clustering method to select training data}},
url = {http://dl.acm.org/citation.cfm?id=1454295.1454302},
volume = {19},
year = {2008}
}
@inproceedings{Balcan2008,
author = {Balcan, M F and Hanneke, S and Wortman, J},
booktitle = {COLT},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//The true sample complexity of active learning - 2008 - Balcan, Hanneke, Wortman.pdf:pdf},
pages = {45--56},
publisher = {Springer},
title = {{The true sample complexity of active learning}},
year = {2008}
}
@article{Donmez2010,
author = {Donmez, Pinar and Carbonell, Jaime G},
journal = {Machine Learning},
pages = {97--120},
title = {{From Active to Proactive Learning Methods}},
year = {2010}
}
@inproceedings{Zhu1999,
author = {Zhu, Jun and Yang, Qiang},
booktitle = {International Joint Conference on Artificial Intelligence},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Remembering to add competence-preserving case-addition policies for case-base maintenance - 1999 - Zhu, Yang.pdf:pdf},
pages = {234--241},
publisher = {Citeseer},
title = {{Remembering to add: competence-preserving case-addition policies for case-base maintenance}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.48.2713\&amp;rep=rep1\&amp;type=pdf},
volume = {16},
year = {1999}
}
@article{Zhu2008,
address = {Morristown, NJ, USA},
author = {Zhu, Jingbo and Wang, Huizhen and Yao, Tianshun and Tsou, Benjamin K.},
doi = {10.3115/1599081.1599224},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Active learning with sampling by uncertainty and density for word sense disambiguation and text classification - 2008 - Zhu et al.pdf:pdf},
isbn = {9781905593446},
journal = {Proceedings of the 22nd International Conference on Computational Linguistics - COLING '08},
number = {August},
pages = {1137--1144},
publisher = {Association for Computational Linguistics},
title = {{Active learning with sampling by uncertainty and density for word sense disambiguation and text classification}},
url = {http://portal.acm.org/citation.cfm?doid=1599081.1599224},
volume = {1},
year = {2008}
}
@inproceedings{Donmez2008,
author = {Donmez, Pinar and Carbonell, Jaime},
booktitle = {Proceedings of the 10th International Symposium on Artificial Intelligence and Mathematics, Florida, 2008},
title = {{Paired-Sampling in Density-Sensitive Active Learning}},
url = {http://repository.cmu.edu/compsci/268},
year = {2008}
}
@article{Hospedales,
author = {Hospedales, Timothy and Gong, Shaogang},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Finding Rare Classes Adapting Generative and Discriminative Models in Active Learning - 2011 - Hospedales, Gong.pdf:pdf},
journal = {Advances in Knowledge Discovery and},
title = {{Finding Rare Classes: Adapting Generative and Discriminative Models in Active Learning}},
url = {http://www.springerlink.com/index/3R0581PT46325607.pdf},
year = {2011}
}
@incollection{springerlink:10.1007/978-3-540-24775-3_37,
annote = {10.1007/978-3-540-24775-3\_37},
author = {Mandvikar, Amit and Liu, Huan and Motoda, Hiroshi},
booktitle = {Advances in Knowledge Discovery and Data Mining},
editor = {Dai, Honghua and Srikant, Ramakrishnan and Zhang, Chengqi},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Compact Dual Ensembles for Active Learning - 2004 - Mandvikar, Liu, Motoda.pdf:pdf},
isbn = {978-3-540-22064-0},
pages = {293--297},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Compact Dual Ensembles for Active Learning}},
url = {http://dx.doi.org/10.1007/978-3-540-24775-3\_37},
volume = {3056},
year = {2004}
}
@article{Haertel,
author = {Haertel, R and Seppi, KD and Ringger, EK},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Return on investment for active learning - 2009 - Haertel, Seppi, Ringger.pdf:pdf},
journal = {on Cost Sensitive Learning},
pages = {1--8},
title = {{Return on investment for active learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.148.9408\&amp;rep=rep1\&amp;type=pdf},
year = {2009}
}
@incollection{springerlink:10.1007/BFb0056334,
annote = {        From Duplicate 1 (                           Modelling the competence of case-bases                         - Smyth, Barry; McKenna, Elizabeth )
                
10.1007/BFb0056334
        
      },
author = {Smyth, Barry and McKenna, Elizabeth},
booktitle = {Advances in Case-Based Reasoning},
editor = {Smyth, Barry and Cunningham, P\'{a}draig},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Modelling the competence of case-bases - 1998 - Smyth, McKenna.pdf:pdf},
isbn = {978-3-540-64990-8},
pages = {208--220},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Modelling the competence of case-bases}},
url = {http://dx.doi.org/10.1007/BFb0056334},
volume = {1488},
year = {1998}
}
@article{Chakraborty,
author = {Chakraborty, Shayok and Balasubramanian, Vineeth},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//An Optimization Based Framework for Dynamic Batch Mode Active Learning - 2010 - Chakraborty, Balasubramanian.pdf:pdf},
journal = {opt.kyb.tuebingen.mpg.de},
pages = {1--6},
title = {{An Optimization Based Framework for Dynamic Batch Mode Active Learning}},
url = {http://opt.kyb.tuebingen.mpg.de/papers/OPT2010-chakraborty.pdf},
year = {2010}
}
@article{Settles2008,
abstract = {Both multiple-instance learning and active learning are widely employed in image categorization, but generally they are applied separately. This paper studies the integration of these two methods. Different from typical active learning approaches, the sample selection strategy in multiple-instance active learning needs to handle samples in different granularities, that is, instance/region and bag/image. Three types of sample selection strategies are evaluated: (1) selecting bags only; (2) selecting instances only; and (3) selecting both bags and instances. As there is no existing method for the third case, we propose a set kernel based classifier, based on which, a unified bag and/or instance selection criterion and an integrated learning algorithm are built. The experiments on Corel dataset show that selecting both bags and instances outperforms the other two strategies.},
author = {Settles, B and Craven, M and Ray, S},
editor = {Platt, J C and Koller, D and Singer, Y and Roweis, S},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Multiple-Instance Active Learning - 2008 - Settles, Craven, Ray.pdf:pdf},
journal = {Learning},
pages = {1289--1296},
publisher = {Citeseer},
title = {{Multiple-Instance Active Learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.143.6305},
volume = {1},
year = {2008}
}
@incollection{springerlink:10.1007/978-3-642-00831-3_1,
annote = {10.1007/978-3-642-00831-3\_1},
author = {Zhu, Jingbo and Wang, Huizhen and Tsou, Benjamin},
booktitle = {Computer Processing of Oriental Languages. Language Technology for the Knowledge-based Economy},
editor = {Li, Wenjie and Moll\'{a}-Aliod, Diego},
isbn = {978-3-642-00830-6},
pages = {1--10},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Density-Based Re-ranking Technique for Active Learning for Data Annotations}},
url = {http://dx.doi.org/10.1007/978-3-642-00831-3\_1},
volume = {5459},
year = {2009}
}
@article{Ontanon2003,
abstract = {Empirical experiments have shown that storing every case does not automatically improve the accuracy of a CBR system. Therefore, several retain policies have been proposed in order to select which cases to retain. However, all the research done in case retention strategies is done in centralized CBR systems. We focus on multiagent CBR systems, where each agent has a local case base, and where each agent can interact with other agents in the system to solve problems in a collaborative way. We propose several case retention strategies that directly deal with the issue of being in a multiagent CBR system. Those case retention strategies combine ideas from the CBR case retain strategies and from the active learning techniques. Empirical results show that strategies that use collaboration with other agents outperform those strategies where the agents work in isolation. We present experiments in two different scenarios, the first one allowing multiple copies of one case and the second one only allowing one copy of each case. Although it may seem counterintuitive, we show and explain why not allowing multiple copies of each case achieves better results.},
author = {Onta\~{n}\'{o}n, S and Plaza, Enric},
editor = {Bridge, D and Ashley, K},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Collaborative Case Retention Strategies for CBR Agents - 2003 - Onta\~{n}\'{o}n, Plaza.pdf:pdf},
journal = {CaseBased Reasoning Research and Development Proceedings of the Fifth International Conference on CaseBased Reasoning ICCBR03},
pages = {392--406},
publisher = {Springer-Verlag},
title = {{Collaborative Case Retention Strategies for CBR Agents}},
url = {http://dblp.uni-trier.de/db/conf/iccbr/iccbr2003.html\#OntanonP03},
volume = {2689},
year = {2003}
}
@incollection{springerlink:10.1007/11871842_68,
annote = {10.1007/11871842\_68},
author = {K\"{o}rner, Christine and Wrobel, Stefan},
booktitle = {Machine Learning: ECML 2006},
editor = {F\"{u}rnkranz, Johannes and Scheffer, Tobias and Spiliopoulou, Myra},
isbn = {978-3-540-45375-8},
pages = {687--694},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Multi-class Ensemble-Based Active Learning}},
url = {http://dx.doi.org/10.1007/11871842\_68},
volume = {4212},
year = {2006}
}
@article{Delany2005,
author = {Delany, S.J. and Cunningham, P. and Doyle, D. and Zamolotskikh, A.},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Generating estimates of classification confidence for a case-based spam filter - 2005 - Delany et al.pdf:pdf},
journal = {Case-Based Reasoning Research and Development},
pages = {177--190},
publisher = {Springer},
title = {{Generating estimates of classification confidence for a case-based spam filter}},
url = {http://www.springerlink.com/index/79t1wwgpjj8q2vpq.pdf},
year = {2005}
}
@incollection{springerlink:10.1007/978-3-642-02998-1_11,
annote = {        From Duplicate 1 (                           The Good, the Bad and the Incorrectly Classified: Profiling Cases for Case-Base Editing                         - Delany, Sarah )
                
10.1007/978-3-642-02998-1\_11
        
      },
author = {Delany, Sarah},
booktitle = {Case-Based Reasoning Research and Development},
editor = {McGinty, Lorraine and Wilson, David},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/The Good, the Bad and the Incorrectly Classified Profiling Cases for Case-Base Editing - 2009 - Delany.pdf:pdf},
isbn = {978-3-642-02997-4},
pages = {135--149},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{The Good, the Bad and the Incorrectly Classified: Profiling Cases for Case-Base Editing}},
url = {http://dx.doi.org/10.1007/978-3-642-02998-1\_11},
volume = {5650},
year = {2009}
}
@phdthesis{Greene2007,
author = {Greene, Derek},
booktitle = {Philosophy},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//A State-of-the-Art Toolkit for Document Clustering - 2007 - Greene.pdf:pdf},
number = {March},
title = {{A State-of-the-Art Toolkit for Document Clustering}},
year = {2007}
}
@article{Vinzamuri2010,
author = {Vinzamuri, Bhanukiran},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//A Robust Active Learning Framework using Itemset based Dynamic Rule Sampling - 2010 - Vinzamuri.pdf:pdf},
journal = {Architecture},
title = {{A Robust Active Learning Framework using Itemset based Dynamic Rule Sampling}},
year = {2010}
}
@article{Nguyen2004,
address = {New York, New York, USA},
author = {Nguyen, Hieu T. and Smeulders, Arnold},
doi = {10.1145/1015330.1015349},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Active learning using pre-clustering - 2004 - Nguyen, Smeulders.pdf:pdf},
isbn = {1581138285},
journal = {Twenty-first international conference on Machine learning - ICML '04},
pages = {79},
publisher = {ACM Press},
title = {{Active learning using pre-clustering}},
url = {http://portal.acm.org/citation.cfm?doid=1015330.1015349},
year = {2004}
}
@article{RoySamplingEstimation2001,
author = {Roy, Nicholas},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Toward Optimal Active Learning through Sampling Estimation of Error Reduction - 2001 - Roy, McCallum.pdf:pdf},
journal = {LEARNING-INTERNATIONAL WORKSHOP THEN},
title = {{Toward optimal active learning through sampling estimation of error reduction}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.9963\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
