@incollection{springerlink:10.1007/978-3-642-02998-1_11,
annote = {
        From Duplicate 1 ( 
        
          The Good, the Bad and the Incorrectly Classified: Profiling Cases for Case-Base Editing
        
         - Delany, Sarah )

        
        
10.1007/978-3-642-02998-1\_11

        

      },
author = {Delany, Sarah},
booktitle = {Case-Based Reasoning Research and Development},
editor = {McGinty, Lorraine and Wilson, David},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/The Good, the Bad and the Incorrectly Classified Profiling Cases for Case-Base Editing - Delany - 2009.pdf:pdf},
isbn = {978-3-642-02997-4},
pages = {135--149},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{The Good, the Bad and the Incorrectly Classified: Profiling Cases for Case-Base Editing}},
url = {http://dx.doi.org/10.1007/978-3-642-02998-1\_11},
volume = {5650},
year = {2009}
}
@inproceedings{Hu2009,
author = {Hu, Rong and Delany, Sarah Jane and MacNamee, Brian},
booktitle = {Proceedings of the UKDS Workshop at 8th International Conference on Case-based Reasoning (ICCBR 09)},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/EGAL Exploration Guided Active Learning for TCBR - Hu, Jane Delany, Mac Namee - 2010(2).pdf:pdf},
pages = {181--192},
title = {{Sampling with confidence: Using k-nn confidence measures in active learning}},
url = {http://arrow.dit.ie/cgi/viewcontent.cgi?article=1050\&amp;context=scschcomcon},
year = {2009}
}
@incollection{springerlink:10.1007/BFb0056334,
annote = {
        From Duplicate 1 ( 
        
          Modelling the competence of case-bases
        
         - Smyth, Barry; McKenna, Elizabeth )

        
        
10.1007/BFb0056334

        

      },
author = {Smyth, Barry and McKenna, Elizabeth},
booktitle = {Advances in Case-Based Reasoning},
editor = {Smyth, Barry and Cunningham, P\'{a}draig},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Modelling the Competence of Case-Bases - Smyth, Mckenna - Unknown.pdf:pdf},
isbn = {978-3-540-64990-8},
pages = {208--220},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Modelling the competence of case-bases}},
url = {http://dx.doi.org/10.1007/BFb0056334},
volume = {1488},
year = {1998}
}
@incollection{springerlink:10.1007/978-3-642-14274-1_13,
annote = {        From Duplicate 1 (                   EGAL: Exploration Guided Active Learning for TCBR                 - Hu, Rong; Jane Delany, Sarah; Mac Namee, Brian )
                
10.1007/978-3-642-14274-1\_13
        
      },
author = {Hu, Rong and {Jane Delany}, Sarah and {Mac Namee}, Brian},
booktitle = {Case-Based Reasoning. Research and Development},
editor = {Bichindaritz, Isabelle and Montani, Stefania},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/EGAL Exploration guided active learning for TCBR - Hu, Jane Delany, Mac Namee - 2010.pdf:pdf},
isbn = {978-3-642-14273-4},
pages = {156--170},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{EGAL: Exploration Guided Active Learning for TCBR}},
url = {http://dx.doi.org/10.1007/978-3-642-14274-1\_13},
volume = {6176},
year = {2010}
}
@article{Roy1996,
author = {Roy, Nicholas and Mccallum, Andrew and Com, Mccallum Whizbang},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Toward Optimal Active Learning through Monte Carlo Estimation of Error Reduction - Roy, Mccallum, Com - 1996.pdf:pdf},
journal = {Learning},
title = {{Toward Optimal Active Learning through Monte Carlo Estimation of Error Reduction}},
year = {1996}
}
@article{Roy2000,
author = {Roy, Nicholas and Mccallum, Andrew and Com, Mccallum Whizbang},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Toward Optimal Active Learning through Sampling Estimation of Error Reduction - Roy, McCallum - 2001.pdf:pdf},
journal = {Text},
title = {{Toward Optimal Active Learning through Sampling Estimation of Error Reduction Two common \`{E}}},
year = {2000}
}
@article{Zhu2008,
address = {Morristown, NJ, USA},
author = {Zhu, Jingbo and Wang, Huizhen and Yao, Tianshun and Tsou, Benjamin K.},
doi = {10.3115/1599081.1599224},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Active learning with sampling by uncertainty and density for word sense disambiguation and text classification - Zhu et al. - 2008.pdf:pdf},
isbn = {9781905593446},
journal = {Proceedings of the 22nd International Conference on Computational Linguistics - COLING '08},
number = {August},
pages = {1137--1144},
publisher = {Association for Computational Linguistics},
title = {{Active learning with sampling by uncertainty and density for word sense disambiguation and text classification}},
url = {http://portal.acm.org/citation.cfm?doid=1599081.1599224},
volume = {1},
year = {2008}
}
@article{Chakraborty,
author = {Chakraborty, Shayok and Balasubramanian, Vineeth and Panchanathan, Sethuraman},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/An Optimization Based Framework for Dynamic Batch Mode Active Learning - Chakraborty, Balasubramanian, Panchanathan - Unknown.pdf:pdf},
journal = {Computing},
pages = {1--6},
title = {{An Optimization Based Framework for Dynamic Batch Mode Active Learning}}
}
@article{Cebron2007,
author = {Cebron, Nicolas and Berthold, Michael R},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/An Adaptive Multi Objective Selection Strategy for Active Learning An Adaptive Multi Objective Selection Strategy for Active Learning Technical Report - Cebron, Berthold - 2007.pdf:pdf},
title = {{An Adaptive Multi Objective Selection Strategy for Active Learning An Adaptive Multi Objective Selection Strategy for Active Learning Technical Report}},
year = {2007}
}
@article{Haertel,
author = {Haertel, Robbie A and Seppi, Kevin D and Ringger, Eric K and Carroll, James L},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Return on Investment for Active Learning - Haertel et al. - Unknown.pdf:pdf},
journal = {Most},
pages = {1--8},
title = {{Return on Investment for Active Learning}}
}
@article{Cunningham2009,
author = {Cunningham, P.},
doi = {10.1109/TKDE.2008.227},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/A Taxonomy of Similarity Mechanisms for Case-Based Reasoning - Cunningham - 2009.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = nov,
number = {11},
pages = {1532--1543},
title = {{A Taxonomy of Similarity Mechanisms for Case-Based Reasoning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4674351},
volume = {21},
year = {2009}
}
@article{Hospedales,
author = {Hospedales, Timothy and Gong, Shaogang and Xiang, Tao},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Finding Rare Classes Adapting Generative and Discriminative Models in Active Learning - Hospedales, Gong, Xiang - Unknown.pdf:pdf},
title = {{Finding Rare Classes : Adapting Generative and Discriminative Models in Active Learning}}
}
@article{Nguyen2004,
address = {New York, New York, USA},
author = {Nguyen, Hieu T. and Smeulders, Arnold},
doi = {10.1145/1015330.1015349},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Active learning using pre-clustering - Nguyen, Smeulders - 2004.pdf:pdf},
isbn = {1581138285},
journal = {Twenty-first international conference on Machine learning - ICML '04},
pages = {79},
publisher = {ACM Press},
title = {{Active learning using pre-clustering}},
url = {http://portal.acm.org/citation.cfm?doid=1015330.1015349},
year = {2004}
}
@article{Tomanek2011,
author = {Tomanek, Katrin and Morik, Katharina},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Inspecting Sample Reusability for Active Learning - Tomanek, Morik - 2011.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {active learning,covariate shift,sample selection bias,uncertainty sampling},
pages = {169--181},
title = {{Inspecting Sample Reusability for Active Learning}},
volume = {16},
year = {2011}
}
@article{Zhu2008a,
address = {Morristown, NJ, USA},
author = {Zhu, Jingbo and Wang, Huizhen and Hovy, Eduard},
doi = {10.3115/1599081.1599223},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Multi-criteria-based strategy to stop active learning for data annotation - Zhu, Wang, Hovy - 2008.pdf:pdf},
isbn = {9781905593446},
journal = {Proceedings of the 22nd International Conference on Computational Linguistics - COLING '08},
number = {August},
pages = {1129--1136},
publisher = {Association for Computational Linguistics},
title = {{Multi-criteria-based strategy to stop active learning for data annotation}},
url = {http://portal.acm.org/citation.cfm?doid=1599081.1599223},
volume = {1},
year = {2008}
}
@article{He,
author = {He, Jingrui and Carbonell, Jaime},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Nearest-Neighbor-Based Active Learning for Rare Category Detection - He, Carbonell - Unknown.pdf:pdf},
journal = {Processing},
pages = {1--8},
title = {{Nearest-Neighbor-Based Active Learning for Rare Category Detection}}
}
@article{Vinzamuri2010,
author = {Vinzamuri, Bhanukiran},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/A Robust Active Learning Framework using Itemset based Dynamic Rule Sampling - Vinzamuri - 2010.pdf:pdf},
journal = {Architecture},
title = {{A Robust Active Learning Framework using Itemset based Dynamic Rule Sampling}},
year = {2010}
}
@article{Guo2007,
author = {Guo, Yuhong and Schuurmans, Dale},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Discriminative batch mode active learning - Guo, Schuurmans - 2007.pdf:pdf},
journal = {Advances in Neural Information Processing Systems (NIPS)},
pages = {593--600},
publisher = {Citeseer},
title = {{Discriminative batch mode active learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.8661\&amp;rep=rep1\&amp;type=pdf},
year = {2007}
}
@article{Lindstrom2010,
author = {Lindstrom, Patrick and Hu, R. and Delany, S.J. and {Mac Namee}, B.},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/SVM Based Active Learning with Exploration - Lindstrom et al. - 2010.pdf:pdf},
journal = {Electrical Engineering},
pages = {1--3},
title = {{SVM Based Active Learning with Exploration}},
url = {http://arrow.dit.ie/cgi/viewcontent.cgi?article=1127\&amp;context=engscheleart},
year = {2010}
}
@incollection{springerlink:10.1007/978-3-642-00831-3_1,
annote = {10.1007/978-3-642-00831-3\_1},
author = {Zhu, Jingbo and Wang, Huizhen and Tsou, Benjamin},
booktitle = {Computer Processing of Oriental Languages. Language Technology for the Knowledge-based Economy},
editor = {Li, Wenjie and Moll\'{a}-Aliod, Diego},
isbn = {978-3-642-00830-6},
pages = {1--10},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Density-Based Re-ranking Technique for Active Learning for Data Annotations}},
url = {http://dx.doi.org/10.1007/978-3-642-00831-3\_1},
volume = {5459},
year = {2009}
}
@incollection{springerlink:10.1007/11871842_68,
annote = {10.1007/11871842\_68},
author = {K\"{o}rner, Christine and Wrobel, Stefan},
booktitle = {Machine Learning: ECML 2006},
editor = {F\"{u}rnkranz, Johannes and Scheffer, Tobias and Spiliopoulou, Myra},
isbn = {978-3-540-45375-8},
pages = {687--694},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Multi-class Ensemble-Based Active Learning}},
url = {http://dx.doi.org/10.1007/11871842\_68},
volume = {4212},
year = {2006}
}
@incollection{springerlink:10.1007/978-3-540-24775-3_37,
annote = {10.1007/978-3-540-24775-3\_37},
author = {Mandvikar, Amit and Liu, Huan and Motoda, Hiroshi},
booktitle = {Advances in Knowledge Discovery and Data Mining},
editor = {Dai, Honghua and Srikant, Ramakrishnan and Zhang, Chengqi},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Compact Dual Ensembles for Active Learning - Mandvikar, Liu, Motoda - 2004.pdf:pdf},
isbn = {978-3-540-22064-0},
pages = {293--297},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Compact Dual Ensembles for Active Learning}},
url = {http://dx.doi.org/10.1007/978-3-540-24775-3\_37},
volume = {3056},
year = {2004}
}
@inproceedings{Donmez2007,
abstract = {Active Learning methods rely on static strategies for sampling unlabeled point(s). These strategies range from uncertainty sampling and density estimation to multi-factor methods with learn-once-use-always model parameters. This paper proposes a dynamic approach, called DUAL, where the strategy selection parameters are adaptively updated based on estimated future residual error reduction after each actively sampled point. The objective of dual is to outperform static strategies over a large operating range: from very few to very many labeled points. Empirical results over six datasets demonstrate that DUAL outperforms several state-of-the-art methods on most datasets.},
author = {Donmez, Pinar and Carbonell, Jaime G and Bennett, Paul N},
booktitle = {Machine Learning ECML 2007},
doi = {10.1007/978-3-540-74958-5\_14},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Dual strategy active learning - Donmez, Carbonell, Bennett - 2007.pdf:pdf},
isbn = {9783540749578},
pages = {116--127},
publisher = {Springer-Verlag},
series = {ECML '07},
title = {{Dual strategy active learning}},
url = {http://www.springerlink.com/index/325n432605r42282.pdf},
year = {2007}
}
@article{Ontanon2003,
abstract = {Empirical experiments have shown that storing every case does not automatically improve the accuracy of a CBR system. Therefore, several retain policies have been proposed in order to select which cases to retain. However, all the research done in case retention strategies is done in centralized CBR systems. We focus on multiagent CBR systems, where each agent has a local case base, and where each agent can interact with other agents in the system to solve problems in a collaborative way. We propose several case retention strategies that directly deal with the issue of being in a multiagent CBR system. Those case retention strategies combine ideas from the CBR case retain strategies and from the active learning techniques. Empirical results show that strategies that use collaboration with other agents outperform those strategies where the agents work in isolation. We present experiments in two different scenarios, the first one allowing multiple copies of one case and the second one only allowing one copy of each case. Although it may seem counterintuitive, we show and explain why not allowing multiple copies of each case achieves better results.},
author = {Onta\~{n}\'{o}n, S and Plaza, Enric},
editor = {Bridge, D and Ashley, K},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Collaborative Case Retention Strategies for CBR Agents - Onta\~{n}\'{o}n, Plaza - 2003.pdf:pdf},
journal = {CaseBased Reasoning Research and Development Proceedings of the Fifth International Conference on CaseBased Reasoning ICCBR03},
pages = {392--406},
publisher = {Springer-Verlag},
title = {{Collaborative Case Retention Strategies for CBR Agents}},
url = {http://dblp.uni-trier.de/db/conf/iccbr/iccbr2003.html\#OntanonP03},
volume = {2689},
year = {2003}
}
@inproceedings{Roy2001,
abstract = {This paper presents an active learning method that directly optimizes expected future error. This is in contrast to many other popular techniques that instead aim to reduce version space size. These other methods are popular because for many learning models, closed form calculation of the expected future error is intractable. Our approach is made feasible by taking a sampling approach to estimating the expected reduction in error due to the labeling of a query. In experimental results on two real-world data sets we reach high accuracy very quickly, sometimes with four times fewer labeled examples than competing methods.},
author = {Roy, Nick and McCallum, Andrew},
booktitle = {Proc 18th International Conf on Machine Learning},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References//Toward Optimal Active Learning through Sampling Estimation of Error Reduction - Roy, McCallum - 2001.pdf:pdf},
isbn = {1558607781},
pages = {441--448},
publisher = {Citeseer},
title = {{Toward Optimal Active Learning through Sampling Estimation of Error Reduction}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.9963\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@article{Hu2010,
author = {Hu, Rong and Namee, Brian Mac and Delany, Sarah Jane},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Off to a Good Start Using Clustering to Select the Initial Training Set in Active Learning - Hu, Namee, Delany - 2010.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {general conference papers},
number = {Flairs},
pages = {26--31},
title = {{Off to a Good Start : Using Clustering to Select the Initial Training Set in Active Learning}},
year = {2010}
}
@article{Kang2004,
author = {Kang, Jaeho and Ryu, Kwang Ryel and Kwon, Hyuk-Chul},
journal = {Training},
pages = {384--388},
title = {{Using Cluster-Based Sampling to Select Initial Training Set for Active Learning}},
year = {2004}
}
@article{Hu2008,
author = {Hu, R and Namee, B Mac and Delany, SJ},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Sweetening the dataset Using active learning to label unlabelled datasets - Hu, Namee, Delany - 2008.pdf:pdf},
journal = {Proceedings of the the 19th Irish},
title = {{Sweetening the dataset: Using active learning to label unlabelled datasets}},
url = {http://arrow.dit.ie/cgi/viewcontent.cgi?article=1019\&context=scschcomcon},
year = {2008}
}
@article{Beygelzimer2008,
abstract = {We present a practical and statistically consistent scheme for actively learning binary classifiers under general loss functions. Our algorithm uses importance weighting to correct sampling bias, and by controlling the variance, we are able to give rigorous label complexity bounds for the learning process. Experiments on passively labeled data show that this approach reduces the label complexity required to achieve good predictive performance on many learning problems.},
author = {Beygelzimer, Alina and Dasgupta, Sanjoy and Langford, John},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Importance Weighted Active Learning - Beygelzimer, Dasgupta, Langford - 2008.pdf:pdf},
journal = {Proceedings of the 26th Annual International Conference on Machine Learning ICML 09},
number = {ii},
pages = {1--8},
publisher = {ACM Press},
series = {ICML '09},
title = {{Importance Weighted Active Learning}},
url = {http://arxiv.org/abs/0812.4952},
volume = {abs/0812.4},
year = {2008}
}
@inproceedings{Balcan2008,
author = {Balcan, M F and Hanneke, S and Wortman, J},
booktitle = {COLT},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/The true sample complexity of active learning - Balcan, Hanneke, Wortman - 2008.pdf:pdf},
pages = {45--56},
publisher = {Springer},
title = {{The true sample complexity of active learning}},
year = {2008}
}
@article{Settles2008,
abstract = {Both multiple-instance learning and active learning are widely employed in image categorization, but generally they are applied separately. This paper studies the integration of these two methods. Different from typical active learning approaches, the sample selection strategy in multiple-instance active learning needs to handle samples in different granularities, that is, instance/region and bag/image. Three types of sample selection strategies are evaluated: (1) selecting bags only; (2) selecting instances only; and (3) selecting both bags and instances. As there is no existing method for the third case, we propose a set kernel based classifier, based on which, a unified bag and/or instance selection criterion and an integrated learning algorithm are built. The experiments on Corel dataset show that selecting both bags and instances outperforms the other two strategies.},
author = {Settles, B and Craven, M and Ray, S},
editor = {Platt, J C and Koller, D and Singer, Y and Roweis, S},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Multiple-Instance Active Learning - Settles, Craven, Ray - 2008.pdf:pdf},
journal = {Learning},
pages = {1289--1296},
publisher = {Citeseer},
title = {{Multiple-Instance Active Learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.143.6305},
volume = {1},
year = {2008}
}
@article{Cebron2008,
abstract = {Classifying large datasets without any a-priori information poses a problem in numerous tasks. Especially in industrial environments, we often encounter diverse measurement devices and sensors that produce huge amounts of data, but we still rely on a human expert to help give the data a meaningful interpretation. As the amount of data that must be manually classified plays a critical role,we need to reduce the number of learning episodes involving human interactions as much as possible. In addition for real world applications it is fundamental to converge in a stable manner to a solution that is close to the optimal solution. We present a new self-controlled exploration/exploitation strategy to select data points to be labeled by a domain expert where the potential of each data point is computed based on a combination of its representativeness and the uncertainty of the classifier. A new Prototype Based Active Learning (PBAC) algorithm for classification is introduced. We compare the results to other active learning approaches on several benchmark datasets.},
author = {Cebron, Nicolas and Berthold, Michael R.},
doi = {10.1007/s10618-008-0115-0},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Active learning for object classification from exploration to exploitation - Cebron, Berthold - 2008.pdf:pdf},
issn = {13845810},
journal = {Data Mining and Knowledge Discovery},
keywords = {active learning,data mining,exploitation,exploration,prototype classification,subtractive clustering},
month = jul,
number = {2},
pages = {283--299},
title = {{Active learning for object classification: from exploration to exploitation}},
url = {http://www.springerlink.com/index/10.1007/s10618-008-0115-0},
volume = {18},
year = {2008}
}
@inproceedings{Bondu2010,
author = {Bondu, A and Lemaire, V and Boull\'{e}, M},
booktitle = {Computational Intelligence},
file = {:C$\backslash$:/Users/Charles Mc/Dropbox/College/4th Year/FYP/References/Exploration vs . exploitation in active learning a Bayesian approach - Bondu, Lemaire, Boull\'{e} - 2010.pdf:pdf},
pages = {18--23},
publisher = {IEEE},
title = {{Exploration vs . exploitation in active learning : a Bayesian approach}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5596815},
year = {2010}
}
